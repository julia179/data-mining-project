\documentclass[12pt, a4paper]{article}
\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage[top=2.5cm, bottom=2.5cm, left=0.5cm, right=0.5cm]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref}
\usepackage{anyfontsize}
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{latexsym}
\usepackage{amsfonts}
\usepackage{longtable}
\usepackage{array}
\usepackage{Sweave}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  filecolor=magenta,      
  urlcolor=cyan,
}
\urlstyle{same}
<<ustawienia_globalne, echo=FALSE, warning=FALSE>>=
  library(knitr)
library(xtable)
opts_chunk$set(options(Encoding="UTF-8"),cache=FALSE,fig.path='figure/', fig.align='center', fig.pos='H',fig.width=7, fig.height=4)
set.seed(41)
@
  \begin{document}

\title{Pozyskiwanie Wiedzy\\
  Projekt - Część II}
\author{Justyna Domańska i Julia Lenczewska}
\maketitle
\tableofcontents
\newpage
\section{Cel raportu}
W tym raporcie zajmiemy się dalszą analizą zbioru danych {\it German Credit}. Najpierw przeprowadzimy analizę skupień - przeanalizujemy algorytmy takie jak k-means, PAM, AGNES i DIANA. W kolejnym etapie zastosujemy redukcję wymiaru i porównamy wyniki analizy skupień oraz klasyfikacji, otrzymane dla danych przed i po zastosowaniu redukcji.

<<echo=FALSE>>=
  library(MASS)
library(cluster)
dane <- read.table("german.data")
colnames(dane) <- c("Status of existing checking account","Duration in month",
                    "Credit history","Purpose","Credit amount","Savings account",
                    "Present employment since","Installment rate in percentage of disposable income",
                    "Personal status and sex","Other debtors","Present residence since",
                    "Property","Age in years","Other installment plans","Housing",
                    "Number of existing credits at this bank","Job","Number of people being liable to provide maintenance for",
                    "Telephone","foreign worker","creditability")
#dane$creditability <- as.factor(ifelse(dane$creditability == 2, 1,0)) # skoro potem dzieli na klastry 1,2 to chyba nie trzeba tu zmieniać na 0,1
attach(dane)
@
  
  \section{Analiza skupień}
\subsection{k-means}
Jednym z głównych i najcześciej stosowanych algorytmów analizy skupień jest algorytm k-means. 
Nie możemy go jednak zastosować do wszystkich danych jakimi dysponujemy, gdyż algorytmu tego nie stosuje się do danych jakościowych lub mieszanych typów. W związku z tym do przeprowadzenia analizy bazującej na algorytmie k-średnich wykorzystamy jedynie zmienne numeryczne. Wybierzemy te same zmienne, które w pierwszej części raportu użyte zostały m.in. przy algorytmie k-NN. Będą to: Duration in month, Credit amount, Installment rate in percentage of disposable income, Present residence since,  Age in years, Number of existing credits at this bank, Number of people being liable to provide maintenance for.
<<echo=FALSE>>=
  dane1 <- dane[,1:20] #wyrzucamy creditability
typ <- c()
for (i in 1:dim(dane1)[2]){
  typ[i] <- class(dane1[,i])}
dane1.numeric <- dane1[,which(typ=="integer")]
@
  Ważnym elementem przy stosowaniu algorytmu k-means, jest wybór optymalnej wartości k. Porównamy wartości wskaźników oceniających jakość grupowania dla różnej liczby klastrów. 
\subsubsection{Dla danych przeskalowanych}
\begin{figure}[H]
<<echo=FALSE, eval=TRUE, fig=TRUE, warning=FALSE, message=FALSE>>=
  library(reshape2)
library(ggplot2)
ggplot(data = melt(dane1.numeric[,-2]), aes(x=variable, y=value)) + geom_boxplot(aes(fill=variable))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-ploty dla zmiennych numerycznych z pominięciem Credit amount}\label{fig:box2}
\end{figure}
Na Rysunku \ref{fig:box2} widzimy, że zakresy wartości jakie przyjmują zmienne znacząco się różnią. Zauważmy, że rysunek nie zawiera box-plotu dla zmiennej Credit amount. Maksymalna kwota kredytu wynosi bowiem 18424 marek niemieckich, zatem umieszczenie jej na rysunku tylko zamazałoby obraz. \\W związku z powyższym przed zastosowaniem algorytmu k-średnich przeskalujemy dane wykorzystując w tym celu funkcję {\it scale}. Jako, że znamy liczbę grup, na które w rzeczywistości podzielone są nasze dane, rozpocznijmy od wybrania $k=2$ i sprawdźmy co w takim wypadku otrzymujemy. Porównamy wartości Total Within Sum of Squares dla {\it nstart}=1 , 10 oraz 20. 
<<echo=FALSE>>=
  dane1.numeric.scale <- as.data.frame(scale(dane1.numeric))
kmeans2n1.scale <- kmeans(dane1.numeric.scale, centers=2,iter.max=10, nstart=1)
kmeansn1 <- kmeans2n1.scale$tot.withinss
@
  <<echo=FALSE>>=
  kmeans2n10.scale <- kmeans(dane1.numeric.scale, centers=2,iter.max=10, nstart=10)
kmeansn10 <- kmeans2n10.scale$tot.withinss
etykietki.n10 <- kmeans2n10.scale$cluster
@
  <<echo=FALSE>>=
  kmeans2n20.scale <- kmeans(dane1.numeric.scale, centers=2,iter.max=10, nstart=20)
kmeansn20 <- kmeans2n20.scale$tot.withinss
@
  <<echo=FALSE,results='asis'>>=
  twss <- cbind(kmeansn1,kmeansn10,kmeansn20)
colnames(twss) <- c("nstart=1","nstart=10","nstart=20")
print(xtable(twss,caption="Total Within Sum of Squares dla różnych wartości $nstart$", label="tab:wss"),include.rownames=FALSE)
@
  W Tabeli \ref{tab:wss} widzimy, że dla domyślnej wartości parametru nstart otrzymujemy wyższą wartość Total Within Sum of Squares niż dla np. 10. Dla $nstart$ = 10 i 20 otrzymane wyniki są takie same. 
\\Zilustrujemy teraz wyniki analizy skupień w zestawieniu z rzeczywistymi etykietkami jedynie dla dwóch wybranych zmiennych. Wybierzemy zmienne Credit amount oraz Duration in month. Wyniki są przedstawione na Rysunku \ref{fig:2zmiennekmeans}.
\begin{figure}[H]
<<echo=FALSE>>=
  plot(dane1.numeric.scale$`Credit amount`,dane1.numeric.scale$`Duration in month`   ,col=etykietki.n10,
       pch=as.numeric(dane$creditability), xlab='Credit amount (scaled)', ylab = 'Duration in month (scaled)')
title("Klastrowanie z wykorzystaniem k-means \n kolor -  etykietki z k-means, symbol - etykietki rzeczywiste")

points( kmeans2n10.scale$centers[,c("Credit amount","Duration in month")],pch=16,cex=1.5,col=1:3)
@
  \caption{Porównanie etykietek po zastosowaniu k-means dla k = 2}\label{fig:2zmiennekmeans}
\end{figure}
Na Rysunku \ref{fig:2zmiennekmeans} w jednym klastrze znajdują się obserwacje z wysokimi wartościami zmiennych Credit amount oraz Duration in month, zaś w drugim z niskimi wartościami wymienionych zmiennych.
\\
Przeanalizujemy teraz wartości zmiennych w poszczególnych klastrach. Tabela \ref{tab:sredniekmeans} zawiera średnie wartości zmiennych, zaś Rysunki \ref{fig:boxkmeans2} i \ref{fig:kmeans2credit} przedstawiają ich box-ploty.
<<echo=FALSE, message=FALSE, warning=FALSE>>=
  library(dplyr)
@
  
  <<echo=FALSE, eval=TRUE, results='asis', message=FALSE, warning=FALSE>>=
  srednie.kmeans2 <- dane1.numeric %>%
  mutate(Cluster = kmeans2n10.scale$cluster) %>%
  group_by(Cluster) %>%
  summarise_all("mean")
srednie.kmeans2 <- data.frame(srednie.kmeans2)
library(stringr)
colnames(srednie.kmeans2) <- str_replace_all(colnames(srednie.kmeans2), "\\."," ")
print(xtable(srednie.kmeans2,caption="Średnie wartości zmiennych w klastrach", label="tab:sredniekmeans",align = c("p{3cm}", "p{1.5cm}","p{1.5cm}","p{2cm}","p{2cm}","p{1.5cm}","p{2cm}","p{2cm}", "p{2cm}")),type="latex",table.placement = "H",include.rownames = F)
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  cluster.kmeans2 <- kmeans2n10.scale$cluster
dane.kmeans2 <- data.frame(cbind(dane1.numeric, cluster.kmeans2))
colnames(dane.kmeans2) <- str_replace_all(colnames(dane.kmeans2), "\\."," ")
ggplot(data = melt(dane.kmeans2[,-2],id="cluster kmeans2"), aes(x=variable, y=value)) + geom_boxplot(aes(fill=factor(`cluster kmeans2`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-ploty zmiennych numerycznych z podziałem na klastry}\label{fig:boxkmeans2}
\end{figure}
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ggplot(dane.kmeans2, aes(x=factor(`cluster kmeans2`), y=`Credit amount`))+
  geom_boxplot(aes(fill=factor(`cluster kmeans2`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-plot zmiennej Credit amount z podziałem na klastry}\label{fig:kmeans2credit}
\end{figure}
Z Tabeli \ref{tab:sredniekmeans} możemy odczytać, że do pierwszego klastra zaliczono osoby, które brały większe kredyty, rozłożone na dłuższy okres czasu. Średni czas spłacania kredytu w pierwszym klastrze wynosi 16.44 miesiąca, natomiast w drugim jest ponad dwukrotnie większy i wynosi 37.01. Podobnie, średnie kwoty kredytu w drugim klastrze są znacznie większe niż te w pierwszym (wynoszą one odpowiednio 7432.81 i 2117.93). Takie grupowanie sugeruje, że decyzja o przyznaniu kredytu zależy od tego czy bierze się mały kredyt na krótki okres czasu, czy duży kredyt na długi. Także na Rysunkach \ref{fig:boxkmeans2} oraz \ref{fig:kmeans2credit} widzimy, że obserwacje zostaly przydzielone do klastrów głównie na podstawie czasu trwania kredytu oraz jego kwoty. \\ 
Zobaczymy, jak porównują się etykietki rzeczywiste i przypisane przez algorytm k-means. Ich zestawienie znajduje się w Tabeli \ref{tab:ktable}. 
  <<echo=FALSE, results='asis'>>=
  library(e1071)
etykietki.rzeczywiste <- dane$creditability
etykietki.2means.scale <- kmeans(dane1.numeric.scale,nstart=10,centers=2,iter.max=10)$cluster
tabelka <- table(etykietki.2means.scale,etykietki.rzeczywiste)
print(xtable(tabelka, label="tab:ktable", caption="Macierz kontyngencji - k-means"), type="latex", table.placement="H", include.rownames=TRUE)
@
  Korzystając z funkcji \textit{matchClasses} uzyskujemy procentową zgodność klas rzeczywistych i wskazanych przez algorytm k-means.
<<echo=FALSE>>=
  matchClasses(tabelka, method = 'exact')
@
  Otrzymana wartość jest dość wysoka i wynosi 67,7\%. \\
Kolejnym etapem analizy będzie porównanie wyników algorytmu k-means dla różnych wartości $k$. Optymalną liczbę klastrów spróbujemy wybrać wykorzystując m.in. funkcję \textit{NbClust} (szczegółowe informacje można znaleźć a artykule \textit{NbClust: An R Package for Determining the Relevant Number of Clusters in a Data Set}, Journal of Statistical Software, Volume 61, Issue 6). Wyliczanych jest z jej użyciem 26 różnych wskaźników, m.in. Silhouette, Dunn, Gap Statistic. Skorzystamy także z tzw. "elbow method", która pomaga w wyborze liczby k, na podstawie wartości Total Within Sum of Squares. Przypomnijmy, że wartość Silhouette wyraża się wzorem:
  $$Silhouette=\frac{1}{n}\sum\limits_{i=1}^{n} S(i) \in \left[-1,1\right],$$
  gdzie $S(i)=\frac{b(i)-a(i)}{\max\{a(i),b(i)\}}$, $ a(i)=\frac{1}{n_r-1} \sum\limits_{j \in {C_r/i} d_{ij}}$, $b(i) = \min\limits_{s\neq r}{d_{iC_s}}$, $d_{iC_s}=\frac{1}{n_s} \sum\limits_{j \in C_s} d_{ij}$. \\
Wskaźniki stabilności oceniają spójność klasteryzacji, porównując wyniki z klastrami otrzymanymi po usunięciu jednej z kolumn. 
Rysunek \ref{fig:elbow1} przedstawia wartości Total Within Sum of Squares w zależności od $k$.
\begin{figure}[H]
<<echo=FALSE,fig=TRUE,warning=FALSE,message=FALSE>>=
  library(factoextra)
set.seed(123)
fviz_nbclust(dane1.numeric.scale, kmeans, method = "wss") +
  geom_vline(xintercept = 6, linetype = 2)+
  labs(subtitle = "Elbow method")
@
  \caption{Wykres wartości Total Within Sum of Squares}\label{fig:elbow1}
\end{figure}

Korzystając z "elbow method" wybieramy taką liczbę klastrów, przy której wykres zaczyna się wypłaszczać. Analizując powyższy rysunek trudno wybrać jedno optymalne $k$, może to być np. $k=6$.
% <<echo=FALSE,fig=TRUE>>=
  % silhouette_score <- function(k){
    %   km <- kmeans(dane1.numeric.scale, centers = k,nstart=25)
    %   ss <- silhouette(km$cluster, dist(dane1.numeric.scale))
    %   mean(ss[, 3])
    % }
% k <- 2:6
% avg_sil <- sapply(k, silhouette_score)
% plot(k, type='b', avg_sil, xlab='Number of clusters', ylab='Average Silhouette Scores', frame=FALSE)
% @
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  # Silhouette method
  fviz_nbclust(dane1.numeric.scale, kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method")
@
  \caption{Wykres wartości Silhouette w zależności od liczby klastrów}\label{fig:silh1}
\end{figure}
Rysunek \ref{fig:silh1} wskazuje na to, że najwyższą wartość wskaźnika Silhouette otrzymujemy dla $k=3$.
Na Rysunku \ref{fig:nb1} zostało przedstawione, ile kryteriów z funkcji NbClust wybrało daną wartość $k$.
<<echo=FALSE, fig=TRUE,include=FALSE>>=
  library(NbClust)
kryteria <- NbClust(dane1.numeric.scale, min.nc=2, max.nc=6, method="kmeans")
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  barplot(table(kryteria$Best.n[1,]),
          xlab="Liczba klastrów (k)", ylab="Liczba kryteriów",
          main="Liczba kryteriów wskazujących na daną wartość k")
#table(kryteria$Best.n[1,])
@
  \caption{Liczba kryteriów wybierających daną liczbę klastrów}\label{fig:nb1}
\end{figure}
Z powyższego rysunku odczytujemy, że większość wskaźników przyjmowała optymalne wartości dla $k=5$. Zwróćmy jednak uwagę na to, że funkcja ta nie bierze pod uwagę wskaźników stabilności takich jak: APN, AD, ADM, FOM.\\
W poniższej tabeli porównamy wartości kryteriów: Connectivity, Dunn i Silhouette w zależności od liczby klastrów. W tym celu wykorzystamy funkcję clValid. 
<<echo=FALSE,results='asis', warning=FALSE>>=
  library(clValid)
internal.validation <- clValid(dane1.numeric.scale,nClust=2:6,
                               clMethods = "kmeans",validation = "internal",maxitems=1000)
#summary(internal.validation)
mac1 <- as.data.frame(internal.validation@measures)
colnames(mac1) <- c("k=2","k=3","k=4","k=5","k=6")
print(xtable(mac1,digits=3,caption="Wskaźniki wewnętrzne dla różnych liczb klastrów", label="tab:wsk1"),type="latex",table.placement = "H")
print(xtable(optimalScores(internal.validation),digits=3,caption="Optymalne liczby klastrów w zależności od kryterium", label="tab:wsk2"
),type="latex",table.placement = "H")
@
  Analizując Tabelę \ref{tab:wsk1} zauważamy, że wartości Silhouette nie różnią się znacząco dla różnych liczb klastrów. Z Tabeli \ref{tab:wsk2} odczytujemy, że najwyższą wartość mamy dla $k=4$. Zwróćmy uwagę na to, że z Rysunku \ref{fig:silh1} wynika, że optymalne jest $k = 3$. Zatem prawdopodobne jest, że wykorzystane funkcje mogą obliczać wartość Silhouette w różny sposób. Najmniejszą, czyli najbardziej pożądaną wartość Connectivity mamy dla $k=2$, także wskaźnik Dunn wskazuje na taką liczbę klastrów (najwyższa wartość wskaźnika). Przejdziemy teraz do porównania wskaźników stabilności. 
<<echo=FALSE,results='asis', warning=FALSE>>=
  library(clValid)
internal.validation2 <- clValid(dane1.numeric.scale,nClust=2:6,
                                clMethods = "kmeans",validation = "stability",maxitems=1000)
#summary(internal.validation)
mac2 <- as.data.frame(internal.validation2@measures)
colnames(mac2) <- c("k=2","k=3","k=4","k=5","k=6")
print(xtable(mac2,digits=3,caption="Wskaźniki stabilności dla różnych liczb klastrów", label="tab:wsk3"),type="latex",table.placement = "H")
print(xtable(optimalScores(internal.validation2),digits=3,caption="Optymalne liczby klastrów w zależności od kryterium", label="tab:wsk4"),type="latex",table.placement = "H")
@
  Tabela \ref{tab:wsk3} zawiera wartości wskaźników stabilności takich jak APN, AD, ADM oraz FOM dla $k \in \{2,3,4,5,6\}$. Ponownie widzimy, że wartości są zbliżone dla różnej liczby klastrów. Przykładowo, dla $k=3$ wartość APN jest jedynie o 0.003 większa niż dla $k=5$. W Tabeli \ref{tab:wsk4} widzimy, że jako optymalne $k$ wybierano 5 i 6. Na podstawie przeprowadzonych analiz nie możemy więc jednoznacznie wybrać liczby klastrów. Jednak w związku z tym, że na $k=5$ wskazała większość wskaźników z funkcji NbClust oraz część wskaźników stabilności, sprawdzimy jak wyglądają rozkłady zmiennych w odpowiednich klastrach.
<<echo=FALSE, results='asis'>>=
  library(e1071)
etykietki.rzeczywiste <- dane$creditability
k5 <- kmeans(dane1.numeric.scale,nstart=10,centers=5,iter.max=10)
etykietki.5means.scale <- k5$cluster
@
  
  Podobnie jak po zastosowaniu k-means z $k=2$, przeanalizujemy teraz wartości zmiennych w zależności od przypisanego klastra. Tabela \ref{tab:sredniekmeans5} zawiera średnie wartości zmiennych, zaś Rysunki \ref{fig:box1kmeans5}-\ref{fig:kmeans5credit} przedstawiają ich box-ploty.
<<echo=FALSE, eval=TRUE, results='asis', message=FALSE, warning=FALSE>>=
  srednie.kmeans5 <- dane1.numeric %>%
  mutate(Cluster = k5$cluster) %>%
  group_by(Cluster) %>%
  summarise_all("mean")
srednie.kmeans5 <- data.frame(srednie.kmeans5)
colnames(srednie.kmeans5) <- str_replace_all(colnames(srednie.kmeans5), "\\."," ")
print(xtable(srednie.kmeans5,caption="Średnie wartości zmiennych w klastrach", label="tab:sredniekmeans5",align = c("p{3cm}", "p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{1.5cm}","p{2cm}","p{2cm}", "p{2cm}")),type="latex",table.placement = "H",include.rownames = F)
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  cluster.kmeans5 <- k5$cluster
dane.kmeans5 <- data.frame(cbind(dane1.numeric, cluster.kmeans5))
colnames(dane.kmeans5) <- str_replace_all(colnames(dane.kmeans5), "\\."," ")
ggplot(data = melt(dane.kmeans5[,-c(1,2,5)],id="cluster kmeans5"), aes(x=variable, y=value)) + geom_boxplot(aes(fill=factor(`cluster kmeans5`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-ploty zmiennych numerycznych z podziałem na klastry}\label{fig:box1kmeans5}
\end{figure}
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ggplot(data = melt(dane.kmeans5[,c(1,5,8)],id="cluster kmeans5"), aes(x=variable, y=value)) + geom_boxplot(aes(fill=factor(`cluster kmeans5`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-ploty zmiennych numerycznych z podziałem na klastry}\label{fig:box2kmeans5}
\end{figure}
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ggplot(dane.kmeans5, aes(x=factor(cluster.kmeans5), y=`Credit amount`))+
  geom_boxplot(aes(fill=factor(`cluster kmeans5`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-plot zmiennej Credit amount z podziałem na klastry}\label{fig:kmeans5credit}
\end{figure}

Na powyższych rysunkach i w tabeli widzimy, że do jednego z klastrów trafiły obserwacje z wysokimi wartościami zmiennych Credit amount i Duration in month. W innym klastrze znajdują się klienci starsi niż w pozostałych. Trudno jednak zrozumieć, dlaczego optymalną liczbą klastrów miałaby być liczba 5.
\subsubsection{Dla danych bez skalowania}
Zobaczymy, jak zmieniłyby się wyniki, gdybyśmy nie wykonywali skalowania danych.
\begin{figure}[H]
\centering
<<echo=FALSE,fig=TRUE,warning=FALSE,message=FALSE>>=
  library(factoextra)
set.seed(123)
fviz_nbclust(dane1.numeric, kmeans, method = "wss") +
  geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")
@
  \caption{Wykres wartości Total Within Sum of Squares}\label{fig:elbownscale}
\end{figure} 
Na Rysunku \ref{fig:elbownscale} widzimy, że przy użyciu "elbow method" wybieramy inne $k$ niż w przypadku zastosowania algorytmu do danych przeskalowanych. Powyższy wykres wskazuje na $k=4$. Warto zauważyć, że wartości Total Within Sum of Squares są znacznie wyższe niż te, które uzyskaliśmy wcześniej - po skalowaniu.

% <<echo=FALSE,fig=TRUE>>=
  % silhouette_score2 <- function(k){
    %   km <- kmeans(dane1.numeric, centers = k,nstart=25)
    %   ss <- silhouette(km$cluster, dist(dane1.numeric))
    %   mean(ss[, 3])
    % }
% k <- 2:6
% avg_sil <- sapply(k, silhouette_score2)
% plot(k, type='b', avg_sil, xlab='Number of clusters', ylab='Average Silhouette Scores', frame=FALSE)
% @

  \begin{figure}[H]
\centering
<<echo=FALSE, fig=TRUE>>=
  # Silhouette method
  fviz_nbclust(dane1.numeric, kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method")
@
  \caption{Wykres wartości Silhouette w zależności od liczby klastrów}\label{fig:silhnscale}
\end{figure}
Rysunek \ref{fig:silhnscale} zawiera informacje o wartościach wskaźnika Silhouette. Są one wyższe niż te które otrzymaliśmy dla danych przeskalowanych.
<<echo=FALSE, fig=TRUE,include=FALSE>>=
  library(NbClust)
kryteria2 <- NbClust(dane1.numeric, min.nc=2, max.nc=6, method="kmeans")
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  barplot(table(kryteria2$Best.n[1,]),
          xlab="Liczba klastrów (k)", ylab="Liczba kryteriów",
          main="Liczba kryteriów wskazujących na daną wartość k")
#table(kryteria$Best.n[1,])
@
  \caption{Liczba kryteriów wybierających daną liczbę klastrów}\label{fig:nbnscale}
\end{figure}
Najwięcej kryteriów wybiera jako optymalne $k=2$.
Przejdźmy do oceny jakości grupowania.
<<echo=FALSE,results='asis', warning=FALSE>>=
  library(clValid)
internal.validation3 <- clValid(dane1.numeric,nClust=2:6,
                                clMethods = "kmeans",validation = "internal",maxitems=1000)
#summary(internal.validation)
mac3 <- as.data.frame(internal.validation3@measures)
colnames(mac3) <- c("k=2","k=3","k=4","k=5","k=6")
print(xtable(mac3,digits=3,caption="Wskaźniki wewnętrzne dla różnych liczb klastrów"),type="latex",table.placement = "H")
print(xtable(optimalScores(internal.validation3),digits=3,caption="Optymalne liczby klastrów w zależności od kryterium"),type="latex",table.placement = "H")
@
  Wskaźniki Silhouette i Connectivity wskazują na $k=2$.

<<echo=FALSE,results='asis', warning=FALSE>>=
  library(clValid)
internal.validation4 <- clValid(dane1.numeric,nClust=2:6,
                                clMethods = "kmeans",validation = "stability",maxitems=1000)
#summary(internal.validation)
mac4 <- as.data.frame(internal.validation4@measures)
colnames(mac4) <- c("k=2","k=3","k=4","k=5","k=6")
print(xtable(mac4,digits=3,caption="Wskaźniki stabilności dla różnych liczb klastrów"),type="latex",table.placement = "H")
print(xtable(optimalScores(internal.validation4),digits=3,caption="Optymalne liczby klastrów w zależności od kryterium"),type="latex",table.placement = "H")
@
  Zwróćmy uwagę na wartości wskaźników stabilności. W porównaniu do wyników uzyskanych po skalowaniu danych, otrzymane wartości są bardzo duże. Świadczy to o niskiej jakości grupowania. Ponadto nie otrzymujemy potwierdzenia, że $k=2$ jest optymalne, gdyż każde z kryteriów wybiera inną wartość $k$.
Wykorzystamy teraz macierz kontyngencji. 
<<echo=FALSE, results='asis'>>=
  library(e1071)
etykietki.rzeczywiste <- dane$creditability
etykietki.2means <- kmeans(dane1.numeric,nstart=10,centers=2,iter.max=10)$cluster
tabelka.bs <- table(etykietki.2means,etykietki.rzeczywiste)
print(xtable(tabelka.bs, label="tab:ktablenscale", caption="Macierz kontyngencji - k-means"), type="latex", table.placement="H", include.rownames=TRUE)
@
  <<echo=FALSE>>=
  matchClasses(tabelka.bs, method='exact')
@
Otrzymany procent zgodności klasy przypisanej i rzeczywistej jest dość wysoki i wynosi $67.1\%$.
  \subsection{PAM}
Następnym algorytmem analizy skupień, który zastosujemy do danych, jest algorytm PAM. Jego zaletą jest to, że możemy go zastosować do danych mieszanego typu. Pierwszym krokiem jest wyznaczenie tzw. macierzy niepodobieństwa. Wykorzystujemy w tym celu funkcję {\it daisy}. Jednym z jej argumentów jest {\it metric}, który odpowiada za miarę odmienności. W przypadku kiedy w danych występują zmienne o typie innym niż {\it numeric} automatycznie wybierana jest miara Gowera. Najpierw rozważymy $k=2$.
<<echo=FALSE, warning=FALSE>>=
  # TWorzymy macierz niepodobieństwa
  dane1[,c(2,5,8,11,13,16,18)] <- lapply(dane1[,c(2,5,8,11,13,16,18)], as.numeric)
daisy(dane1, stand=T) -> MacNiepodob
MacNiepodob.matrix <- as.matrix(MacNiepodob)
dane1 <- as.data.frame(dane1)
@
  <<echo=FALSE>>=
  pam2 <- pam(x=MacNiepodob,diss=TRUE,k=2)
pam2$clustering -> etykietki.pam2
@
  Zilustrujmy na początek wyniki analizy skupień dla dwóch wybranych zmiennych. Tak samo jak w przypadku k-means weźmiemy zmienne Credit amount oraz Duration in month.
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  plot(dane1$`Credit amount`,dane1$`Duration in month`   ,col=etykietki.pam2,
       pch=as.numeric(dane$creditability), xlab='Credit amount (scaled)', ylab = 'Duration in month (scaled)')
title("Klastrowanie z wykorzystaniem pam(k=2) \n kolor -  etykietki z pam, symbol - etykietki rzeczywiste")

points(pam2$centers[,c("Credit amount","Duration in month")],pch=16,cex=1.5,col=1:3)
@
  \caption{Porównanie etykietek po zastosowaniu pam dla k = 2}\label{fig:pam2plot}
\end{figure}
Analizując Rysunek \ref{fig:pam2plot} możemy zauważyć, że klastry nie zostały podzielone ze względu na wartości tych dwóch zmiennych tak jak to było w przypadku klastrów powstałych przy użyciu algorytmu 2-means.
\\
Przeanalizujemy teraz wartości zmiennych w zależności od przypisanego klastra. Tabela \ref{tab:sredniepam} zawiera średnie wartości zmiennych, zaś Rysunki \ref{fig:boxpam2} i \ref{fig:pam2credit} przedstawiają ich box-ploty.
<<echo=FALSE, eval=TRUE, results='asis', message=FALSE, warning=FALSE>>=
  srednie.pam2 <- dane1.numeric %>%
  mutate(Cluster = etykietki.pam2) %>%
  group_by(Cluster) %>%
  summarise_all("mean")
srednie.pam2 <- data.frame(srednie.pam2)
library(stringr)
colnames(srednie.pam2) <- str_replace_all(colnames(srednie.pam2), "\\."," ")
print(xtable(srednie.pam2,caption="Średnie wartości zmiennych numerycznych w klastrach", label="tab:sredniepam",align = c("p{3cm}", "p{1.5cm}","p{1.5cm}","p{2cm}","p{2cm}","p{1.5cm}","p{2cm}","p{2cm}", "p{2cm}")),type="latex",table.placement = "H",include.rownames = F)
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  cluster.pam2 <- etykietki.pam2
dane.pam2 <- data.frame(cbind(dane1.numeric, cluster.pam2))
colnames(dane.pam2) <- str_replace_all(colnames(dane.pam2), "\\."," ")
ggplot(data = melt(dane.pam2[,-2],id="cluster pam2"), aes(x=variable, y=value)) + geom_boxplot(aes(fill=factor(`cluster pam2`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-ploty zmiennych numerycznych z podziałem na klastry}\label{fig:boxpam2}
\end{figure}
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ggplot(dane.pam2, aes(x=factor(`cluster pam2`), y=`Credit amount`))+
  geom_boxplot(aes(fill=factor(`cluster pam2`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-plot zmiennej Credit amount z podziałem na klastry}\label{fig:pam2credit}
\end{figure}
Rysunek \ref{fig:boxpam2} potwierdza to co zilustrowaliśmy na Rysunku \ref{fig:pam2plot}, tzn. wartości przyjmowane przez zmienne Credit Amount oraz Duration in Month są porównywalne. Podobnie jest dla pozostałych zmiennych. Zmienne numeryczne przyjmują podobne wartości w obu klastrach.  

<<echo=FALSE, results='asis'>>=
  dane.pam2 <- dane1[,c(1,3,4,6,7,9,10)]
pam.ile.cat <- dane.pam2 %>%
  mutate(cluster = pam2$clustering) %>%
  group_by(cluster) %>%
  do(the.summary = summary(.))
pam.tab.cat <- pam.ile.cat$the.summary
print(xtable(pam.tab.cat[[1]][,-8],align = c("p{2cm}", "p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}"), caption="Statystyki opisowe dla zmiennych jakościowych w klastrze 1",label="tab:tabelkajakosc1"),type="latex",table.placement = "H",include.rownames = F)
print(xtable(pam.tab.cat[[2]][,-8],align = c("p{2cm}", "p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}"), caption="Statystyki opisowe dla zmiennych jakościowych w klastrze 2"),type="latex",table.placement = "H",include.rownames = F)
@
  
  <<echo=FALSE,results='asis'>>=
  tabela2 <- summary(dane1[,c(1,3,4,6,7,9,10)])
print(xtable(tabela2,caption="Statystyki opisowe dla zmiennych jakościowych dla danych przed klasteryzacją",label="tab:statystykijakosciowe",align=c("p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}")),type="latex",table.placement = "H",include.rownames = F)
@
  
  <<echo=FALSE, results='asis'>>=
  dane.pam22 <- dane1[,c(12,14,15,17,19,20)]
pam.ile.cat2 <- dane.pam22 %>%
  mutate(cluster = pam2$clustering) %>%
  group_by(cluster) %>%
  do(the.summary = summary(.))
pam.tab.cat2 <- pam.ile.cat2$the.summary
print(xtable(pam.tab.cat2[[1]][,-7],align = c("p{2cm}", "p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}"), caption="Statystyki opisowe dla zmiennych jakościowych w klastrze 1", label ="tab:statystykijakosciowe3"),type="latex",table.placement = "H",include.rownames = F)
print(xtable(pam.tab.cat2[[2]][,-7],align = c("p{2cm}", "p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}"), caption="Statystyki opisowe dla zmiennych jakościowych w klastrze 2"),type="latex",table.placement = "H",include.rownames = F)
@
  
  <<echo=FALSE,results='asis'>>=
  tabela3 <- summary(dane1[,c(12,14,15,17,19,20)])
print(xtable(tabela3,caption="Statystyki opisowe dla zmiennych jakościowych dla danych przed klasteryzacją",label="tab:statystykijakosciowe2",align=c("p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}","p{2cm}")),type="latex",table.placement = "H",include.rownames = F)
@
  
  Po przeanalizowaniu Tabel \ref{tab:tabelkajakosc1}- \ref{tab:statystykijakosciowe2} możemy zauważyć m.in. że w klastrze drugim stosunek osób, które nie posiadają telefonu (oznaczenie A191) do wszystkich przypisanych do tego klastra wynosi $78\%$. Dla danych z przed podziału na klastry udział ten wynosi około $60\%$. Wydaje się więc, że to czy posiada się telefon czy nie, może mieć znaczący wpływ na przydział do klastra. W pozostałych przypadkach nie widać wyraźnie zwiększonego udziału danych poziomów w klastrach.\\
  
Zobaczymy, jaka liczba $k$ jest wybierana przez wskaźniki oceniające grupowanie.
<<echo=FALSE>>=
  silhouette_score_pam <- function(k){
    km <- pam(x=MacNiepodob,diss=TRUE,k=k)
    ss <- silhouette(km$clustering, MacNiepodob)
    mean(ss[, 3])
  }
@
  <<echo=FALSE>>=
  silh.pam <- c()
for (k in 2:6){
  silh.pam[k] <- silhouette_score_pam(k)
}
@
  <<echo=FALSE>>=
  k <- 2:6
silh.pam <- silh.pam[-1]
dane.do.wykresu <- as.data.frame(cbind(k,silh.pam))
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ggplot()+geom_line(data=dane.do.wykresu, aes(x=k, y=silh.pam))+geom_point(aes(x=k, y=silh.pam),color="black",size=3)
@
  \caption{Wartości wskaźnika Silhouette w zależności od liczby klastrów}\label{fig:silhpam}
\end{figure}

% To  miało robić wskaźniki stabilności,  używając stability - funkcję w clValid, na dole w dokumentacji jest przykład, ale to co na dole niestety nie chce się policzyć :(
% 
% <<echo=FALSE>>=
  % #pam.stab <- matrix(0,nrow=5,ncol=4)
% Dist <- daisy(dane1, stand=T)
% Dist <- as.matrix(Dist)
% clusterObj <- pam(Dist, diss=TRUE, k=3)
% cluster <- clusterObj$clustering
% 
% stab <- matrix(0,nrow=ncol(DistDel),ncol=4)
% colnames(stab) <- c("APN","AD","ADM","FOM")
%  DistDel <- daisy(dane1,stand=T)
%  DistDel <- as.matrix(DistDel)
% for (del in 1:ncol(DistDel)) {
  %   matDel <- DistDel[,-del]
  %   #DistDel <- daisy(matDel,stand=T)
  %   clusterObjDel <- pam(matDel,diss=TRUE,k=3)
  %   clusterDel <- clusterObjDel$clustering
  %   stab[del,] <- stability(DistDel, Dist=NULL,  del, cluster, clusterDel)
  % }
% pam.stab <- colMeans(stab)
% @
  % <<echo=FALSE, results='asis'>>=
  % print(xtable(pam.stab))
% @

Z powyższego rysunku odczytujemy, że największą wartość Silhouette mamy dla $k=2$.

\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  dunn.pam <- c()
for (i in 2:6){
  pam.do.dunn <- pam(x=MacNiepodob,diss=TRUE,k=i)
  pam.do.dunn$clustering -> etykietki.pam.do.dunn
  dunn.pam[i-1] <- dunn(as.matrix(MacNiepodob), etykietki.pam.do.dunn, Data=NULL)}
dane.do.wykresu.dunn <- as.data.frame(cbind(k,dunn.pam))
ggplot()+geom_line(data=dane.do.wykresu.dunn, aes(x=k, y=dunn.pam))+geom_point(aes(x=k, y=dunn.pam),color="black",size=3)
@
  \caption{Wartości wskaźnika Dunn dla różnej liczby klastrów}\label{fig:dunnpam}
\end{figure}

Na powyższym rysunku widzimy, że wskaźnik Dunn jest najwyższy dla $k=3$.
\\
Do oceny zastosujemy teraz tzw. miary zewnętrzne, które porównują przypisane klasy z rzeczywistymi. Najprostszym sposobem jest wykorzystanie macierzy kontyngencji. 

<<echo=FALSE,results='asis'>>=
  tabelka.pam2 <- table(etykietki.pam2,etykietki.rzeczywiste)
print(xtable(tabelka.pam2, caption="Macierz kontyngencji - PAM", label="tab:etykpam2"),type="latex",table.placement = "H",include.rownames = TRUE)
@
  <<echo=FALSE>>=
  matchClasses(tabelka.pam2, method='exact')
@
Otrzymany procent zgodności klas rzeczywistych i przypisanych nie jest szczególnie wysoki - wynosi $54,2\%$.
  \subsection{AGNES}
Przejdziemy teraz do zastosowania metod hierarchicznych. Jako pierwszą zastosujemy metodę aglomeracyjną AGNES. Porównamy trzy metody łączenia klastrów: average, single, complete.
\subsubsection{average linkage}
Rysunek \ref{fig:agnesavg} przedstawia dendrogram, zaś na Rysunku \ref{fig:agnesavg2} znajduje się dendrogram z zaznaczonymi klasami rzeczywistymi.
<<echo=FALSE>>=
  agnes.avg <- agnes(x=MacNiepodob,diss=TRUE,method="average")
agnes.single <- agnes(x=MacNiepodob,diss=TRUE,method="single")
agnes.complete <- agnes(x=MacNiepodob,diss=TRUE,method="complete")
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  par(cex=0.6)
plot(agnes.avg,which.plots=2,main="AGNES: average linkage")
@
  \caption{Dendrogram - AGNES - average linkage}\label{fig:agnesavg}
\end{figure}
<<echo=FALSE>>=
  # kolorowanie liści dendrogramu
  # kolory == rzeczywiste klasy 
  etykietki.kolory <- as.numeric(dane$creditability) #1 lub 2
kolory.nazwy     <- levels(as.factor(dane$creditability))

# pomocnicza funkcja do kolorowania liści w dendrogramie
col.labels <<- function(node) 
{  
  if(is.leaf(node)) 
  {
    a <- attributes(node)
    label <- attr(node, "label")
    attr(node, "nodePar") <-  c(a$nodePar, list(lab.col = etykietki.kolory[label]))
  }      
  
  return(node)
}
@
  
  <<echo=FALSE>>=
  #--- Odcinanie drzewa klastrow (dedrogramu) dla zadanej liczby klastrów  -----------------------------
agnes.avg.k2 <- cutree(agnes.avg,k=2) # etykietki klastrow
@
  <<echo=FALSE>>=
  #--- Wskaźniki silhouette dla metod hierarchicznych --------------------------------------------------
sil.agnes <- silhouette(x=agnes.avg.k2,dist=MacNiepodob)
# średnią wartość silhouette dla każdego klastra możemy otrzymać następująco##
#(sil.srednie.w.klastrach <- summary(sil.agnes)$clus.avg.widths)
@
  
  \begin{figure}[H]
<<echo=FALSE,fig=TRUE>>=
  hc.kol.avg <- dendrapply(as.dendrogram(agnes.avg), col.labels)
# rysuj dendrogram
par(cex=0.7)
plot(hc.kol.avg)
legend("topright", legend=kolory.nazwy, col=1:3, pch=15, bg="azure2", cex=1.5)
@
  \caption{Dendrogram - AGNES - average linkage z etykietkami rzeczywistymi}\label{fig:agnesavg2}
\end{figure}

% \begin{figure}[H]
% <<echo=FALSE, fig=TRUE>>=
  % fviz_dend(agnes.avg, cex = 0.5, k = 2, color_labels_by_k = TRUE)
% @
  % \caption{AGNES - average linkage dla k=2}\label{fig:agnesavgk2}
% \end{figure}
Poniższa tabela przedstawia macierz kontyngencji dla $k=2$.
<<echo=FALSE,results='asis'>>=
  tabelka.agnes.avg2<- table(agnes.avg.k2,etykietki.rzeczywiste)
print(xtable(tabelka.agnes.avg2, caption="Macierz kontyngencji - AGNES - average linkage", label="tab:etykagnesavg2"),type="latex",table.placement = "H",include.rownames = TRUE)
@

  <<echo=FALSE>>=
  matchClasses(tabelka.agnes.avg2, method='exact')
@
   Zauważmy, że po klasteryzacji otrzymaliśmy zaledwie dwie obserwacje w jednym klastrze. W związku z tym, dalsza analiza traci sens. Również w przypadku wybrania $k=3$, prawie wszystkie obserwacje należą do jednego klastra.

<<echo=FALSE>>=
  silhouette_score_agnesavg <- function(k){
    agnes.avg.k <- cutree(agnes.avg,k=k) 
    sil.agnes <- silhouette(x=agnes.avg.k,dist=MacNiepodob)
    mean(sil.agnes[, 3])
  }

silh.agnes.avg <- c()
for (k in 2:6){
  silh.agnes.avg[k] <- silhouette_score_agnesavg(k)
}
@
  <<echo=FALSE>>=
  k <- 2:6
silh.agnes.avg <- silh.agnes.avg[-1]
dane.do.wykresu1 <- as.data.frame(cbind(k,silh.agnes.avg))
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ggplot()+geom_line(data=dane.do.wykresu1, aes(x=k, y=silh.agnes.avg))+geom_point(aes(x=k, y=silh.agnes.avg),color="black",size=3)
@
  \caption{Wartości wskaźnika Silhouette w zależności od liczby klastrów}\label{fig:silhagnesavg}
\end{figure}
Z Rysunku \ref{fig:silhagnesavg} odczytujemy, że najwyższą wartość Silhouette mamy dla $k=2$, jednak wartość ta jest stosunkowo niska. Dla wyższych $k$ wartość coraz bardziej zbliża się do 0. Na tę samą liczbę klastrów wskazuje także wskaźnik DUNN. Dla większych $k$ widzimy tendencję malejącą.

\begin{figure}[H]
<<echo=FALSE,fig=TRUE>>=
dunn.agnes.avg <- c()
for (i in 2:6){
agnes.avg.nr.k <-  cutree(agnes.avg,k=i)
dunn.agnes.avg[i-1] <- dunn(as.matrix(MacNiepodob), agnes.avg.nr.k, Data=NULL)}
dane.do.wykresu.dunn.aga <- as.data.frame(cbind(k,dunn.agnes.avg))
ggplot()+geom_line(data=dane.do.wykresu.dunn.aga, aes(x=k, y=dunn.agnes.avg))+geom_point(aes(x=k, y=dunn.agnes.avg),color="black",size=3)
@
  \caption{Wartości wskaźnika Dunn dla różnej liczby klastrów}\label{fig:dunnagnesavg}
\end{figure}

\subsubsection{single linkage}
Dendrogram oraz dendrogram z etykietkami rzeczywistymi dla metody łączenia single zostały przedstawione na Rysunkach \ref{fig:agnessingle} i \ref{fig:agnessingle2}.
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  par(cex=0.6)
plot(agnes.single,which.plots=2,main="AGNES: single linkage")
@
  \caption{Dendrogram - AGNES - single linkage}\label{fig:agnessingle}
\end{figure}

<<echo=FALSE>>=
agnes.single.k2 <- cutree(agnes.single,k=2)
sil.agnes.single <- silhouette(x=agnes.single.k2,dist=MacNiepodob)
#(sil.srednie.w.klastrach.single <- summary(sil.agnes.single)$clus.avg.widths)
@
  
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  hc.kol.single <- dendrapply(as.dendrogram(agnes.single), col.labels)
par(cex=0.7)
plot(hc.kol.single)
legend("topright", legend=kolory.nazwy, col=1:3, pch=15, bg="azure2", cex=1.5)
@
  \caption{Dendrogram - AGNES - single linkage z etykietkami rzeczywistymi}\label{fig:agnessingle2}
\end{figure}

% \begin{figure}[H]
% <<echo=FALSE, fig=TRUE>>=
  % fviz_dend(agnes.single, cex = 0.5, k = 2, color_labels_by_k = TRUE)
% @
  % \caption{AGNES - single linkage dla k=2}\label{fig:agnessinglek2}
% \end{figure}

Macierz kontyngencji dla $k=2$ znajduje się w Tabeli \ref{tab:etykagnessingle2}.
<<echo=FALSE,results='asis'>>=
  tabelka.agnes.single2<- table(agnes.single.k2,etykietki.rzeczywiste)
print(xtable(tabelka.agnes.single2, caption="Macierz kontyngencji - AGNES - single linkage", label="tab:etykagnessingle2"),type="latex",table.placement = "H",include.rownames = TRUE)
@
  <<echo=FALSE>>=
  matchClasses(tabelka.agnes.single2, method='exact')
@
  W przypadku tej metody łączenia otrzymujemy podobne wnioski jak poprzednio. Po klasteryzacji otrzymaliśmy zaledwie jedną obserwację w jednym z klastrów. Ponownie więc dalsza analiza traci sens. Również w przypadku wybrania $k=3$, prawie wszystkie obserwacje należą do jednego klastra.

<<echo=FALSE>>=
  silhouette_score_agnessingle <- function(k){
    agnes.single.k <- cutree(agnes.single,k=k) 
    sil.agnes <- silhouette(x=agnes.single.k,dist=MacNiepodob)
    mean(sil.agnes[, 3])
  }

silh.agnes.single <- c()
for (k in 2:6){
  silh.agnes.single[k] <- silhouette_score_agnessingle(k)
}
@
  <<echo=FALSE>>=
  k <- 2:6
silh.agnes.single <- silh.agnes.single[-1]
dane.do.wykresu2 <- as.data.frame(cbind(k,silh.agnes.single))
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ggplot()+geom_line(data=dane.do.wykresu2, aes(x=k, y=silh.agnes.single))+geom_point(aes(x=k, y=silh.agnes.single),color="black",size=3)
@
  \caption{Wartości wskaźnika Silhouette w zależności od liczby klastrów}\label{fig:silhagnessingle}
\end{figure}

\begin{figure}[H]
<<echo=FALSE,fig=TRUE>>=
dunn.agnes.single <- c()
for (i in 2:6){
  agnes.single.nr.k <- cutree(agnes.single,k=i)
  dunn.agnes.single[i-1] <- dunn(as.matrix(MacNiepodob), agnes.single.nr.k, Data=NULL)}
dane.do.wykresu.dunn.ags <- as.data.frame(cbind(k,dunn.agnes.single))
ggplot()+geom_line(data=dane.do.wykresu.dunn.ags, aes(x=k, y=dunn.agnes.single))+geom_point(aes(x=k, y=dunn.agnes.single),color="black",size=3)
@
  \caption{Wartości wskaźnika Dunn dla różnej liczby klastrów}\label{fig:dunnagnessingle}
\end{figure}

Ponownie jak w przypadku average linkage najwyższą wartość Silhouette otrzymujemy dla $k=2$. Wartość ta jest nieznacznie wyższa niż dla poprzedniej metody łączenia. 

\subsubsection{complete linkage}
Na Rysunkach \ref{fig:agnescomplete} i \ref{fig:agnescomplete2} znajdują się odpowiednio - dendrogram i dendrogram z klasami rzeczywistymi.
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  par(cex=0.6)
plot(agnes.complete,which.plots=2, main="AGNES: complete linkage")
@
  \caption{Dendrogram - AGNES - complete linkage}\label{fig:agnescomplete}
\end{figure}

<<echo=FALSE>>=
agnes.complete.k2 <- cutree(agnes.complete,k=2) 
sil.agnes.complete <- silhouette(x=agnes.complete.k2,dist=MacNiepodob)
#(sil.srednie.w.klastrach.complete <- summary(sil.agnes.complete)$clus.avg.widths)
@
  
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  hc.kol.complete <- dendrapply(as.dendrogram(agnes.complete), col.labels)
par(cex=0.7)
plot(hc.kol.complete)
legend("topright", legend=kolory.nazwy, col=1:3, pch=15, bg="azure2", cex=1.5)
@
  \caption{Dendrogram - AGNES - complete linkage z etykietkami rzeczywistymi}\label{fig:agnescomplete2}
\end{figure}

% \begin{figure}[H]
% <<echo=FALSE, fig=TRUE>>=
  % fviz_dend(agnes.complete, cex = 0.5, k = 2, color_labels_by_k = TRUE)
% @
  % \caption{AGNES - average complete dla k=2}\label{fig:agnescompletek2}
% \end{figure}

Poniżej przedstawiamy macierz kontyngencji dla $k=2$.
<<echo=FALSE,results='asis'>>=
  tabelka.agnes.complete2<- table(agnes.complete.k2,etykietki.rzeczywiste)
print(xtable(tabelka.agnes.complete2, caption="Macierz kontyngencji - AGNES - complete linkage", label="tab:etykagnescomplete2"),type="latex",table.placement = "H",include.rownames = TRUE)
@
  <<echo=FALSE>>=
  matchClasses(tabelka.agnes.complete2, method='exact')
@
  
  W przypadku tej metody łączenia uzyskujemy lepsze wyniki niż dla poprzednich. Mniej liczny klaster zawiera 105 obserwacji, a zgodność klas rzeczywistych i przypisanych wynosi $68.9\%$.  Jednak nie zamieszczamy informacji o rozkładzie wartości poszczególnych zmiennych w klastrach, ponieważ podobnie jak w przypadku PAM, trudno jest z nich wysnuć jednoznaczne wnioski. 

<<echo=FALSE>>=
  silhouette_score_agnescomplete <- function(k){
    agnes.complete.k <- cutree(agnes.complete,k=k) 
    sil.agnes <- silhouette(x=agnes.complete.k,dist=MacNiepodob)
    mean(sil.agnes[, 3])
  }

silh.agnes.complete <- c()
for (k in 2:6){
  silh.agnes.complete[k] <- silhouette_score_agnescomplete(k)
}
@
  <<echo=FALSE>>=
  k <- 2:6
silh.agnes.complete <- silh.agnes.complete[-1]
dane.do.wykresu3 <- as.data.frame(cbind(k,silh.agnes.complete))
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ggplot()+geom_line(data=dane.do.wykresu3, aes(x=k, y=silh.agnes.complete))+geom_point(aes(x=k, y=silh.agnes.complete),color="black",size=3)
@
  \caption{Wartości wskaźnika Silhouette w zależności od liczby klastrów}\label{fig:silhagnescomplete}
\end{figure}

\begin{figure}[H]
<<echo=FALSE,fig=TRUE>>=
dunn.agnes.complete <- c()
for (i in 2:6){
  agnes.complete.nr.k <- cutree(agnes.complete,k=i)
  dunn.agnes.complete[i-1] <- dunn(as.matrix(MacNiepodob), agnes.complete.nr.k, Data=NULL)}
dane.do.wykresu.dunn.agc <- as.data.frame(cbind(k,dunn.agnes.complete))
ggplot()+geom_line(data=dane.do.wykresu.dunn.ags, aes(x=k, y=dunn.agnes.complete))+geom_point(aes(x=k, y=dunn.agnes.complete),color="black",size=3)
@
  \caption{Wartości wskaźnika Dunn dla różnej liczby klastrów}\label{fig:dunnagnesecomplete}
\end{figure}

Na Rysunku \ref{fig:silhagnescomplete} widzimy, że najwyższą wartość Silhouette otrzymujemy dla $k=2$. Dla większej liczby klastrów obserwujemy znaczne obniżenie wartości rozważanego wskaźnika. Zastosowanie wyłącznie tej metody sugerowałoby więc, że najlepszym wyborem jest podział na 2 klastry. Również wskaźnik Dunn wskazuje na podział na 2 klastry. Ze względu na występujące w danych zmienne typu factor, nie udało się obliczyć wskaźników oceniających stabilność. Funkcja, która wykorzystana została wcześniej, (clValid) działa bowiem prawidłowo jedynie dla zmiennych numerycznych. Także wyznaczenie tych wskaźników przy użyciu funkcji stability nie powiodło się ze względu na bardzo długi czas obliczeń.

\subsection{DIANA}
Zastosujemy kolejną metodę hierarchiczną, tym razem dzielącą. Będzie to algorytm DIANA. Rysunek \ref{fig:diana} przedstawia dendrogram, zaś na Rysunku \ref{fig:diana2} zaznaczyliśmy na nim klasy rzeczywiste.
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  diana <- diana(x=MacNiepodob,diss=TRUE)
par(cex=0.6)
plot(diana,which.plot=2, main="DIANA")
@
  \caption{Dendrogram - DIANA}\label{fig:diana}
\end{figure}

<<echo=FALSE, fig=TRUE>>=
  # Odcinamy drzewo tak aby uzyskac dokladnie K=2 klastry
  diana.k2 <- cutree(diana,k=2) # etykietki klastrow
@
  
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  hc.kol12 <- dendrapply(as.dendrogram(diana), col.labels)

# rysuj dendrogram
par(cex=0.7)
plot(hc.kol12)
legend("topright", legend=kolory.nazwy, col=1:3, pch=15, bg="azure2", cex=1.5)
@
  \caption{Dendrogram - DIANA z etykietkami rzeczywistymi}\label{fig:diana2}
\end{figure}

Na Rysunkach \ref{fig:sildiana} i \ref{fig:dunndiana} znajdują się wykresy wartości Silhouette i Dunn w zależności od liczby klastrów.
<<echo=FALSE>>=
  silhouette_score_diana <- function(k){
    diana.k <- cutree(diana,k=k) 
    sil.diana <- silhouette(x=diana.k,dist=MacNiepodob)
    mean(sil.diana[, 3])
  }

silh.diana <- c()
for (k in 2:6){
  silh.diana[k] <- silhouette_score_diana(k)
}
@
  <<echo=FALSE>>=
  k <- 2:6
silh.diana <- silh.diana[-1]
dane.do.wykresu4 <- as.data.frame(cbind(k,silh.diana))
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ggplot()+geom_line(data=dane.do.wykresu4, aes(x=k, y=silh.diana))+geom_point(aes(x=k, y=silh.diana),color="black",size=3)
@
  \caption{Wartości wskaźnika Silhouette w zależności od liczby klastrów}\label{fig:sildiana}
\end{figure}

\begin{figure}[H]
<<echo=FALSE,fig=TRUE>>=
dunn.diana <- c()
k <- 2:6
for (i in 2:6){
  diana.do.dunn <- cutree(diana,k=i)
  dunn.diana[i-1] <- dunn(as.matrix(MacNiepodob), diana.do.dunn, Data=NULL)}
dane.do.wykresu.dunn.diana <- as.data.frame(cbind(k,dunn.diana))
ggplot()+geom_line(data=dane.do.wykresu.dunn.diana, aes(x=k, y=dunn.diana))+geom_point(aes(x=k, y=dunn.diana),color="black",size=3)
@
  \caption{Wartości wskaźnika Dunn dla różnej liczby klastrów}\label{fig:dunndiana}
\end{figure}

Najwyższą wartość Silhouette obserwujemy dla $k=2$. Dla $k=3$ widoczny jest nagły spadek wartości, po czym dla kolejnych $k$ możemy zaobserwować wzrost wartości. W przypadku wskaźnika Dunn, najwyższą jego wartość mamy dla $k=6$. Nie możemy jednak wykluczyć, że dla większej liczby klastrów nie uzyskalibyśmy wyższych wyników, gdyż widać tendencję rosnącą.

Tabela \ref{tab:etykdiana2} przedstawia macierz kontyngencji dla $k=2$.
<<echo=FALSE,results='asis'>>=
  tabelka.diana2<- table(diana.k2,etykietki.rzeczywiste)
print(xtable(tabelka.diana2, caption="Macierz kontyngencji - DIANA", label="tab:etykdiana2"),type="latex",table.placement = "H",include.rownames = T)
@
  <<echo=FALSE>>=
  matchClasses(tabelka.diana2, method='exact')
@
  Uzyskany wyżej wynik jest niższy niż wyniki otrzymane dla większości omawianych wcześniej algorytmów.\\
Sprawdzimy, jak rozkładają się wartości poszczególnych zmiennych w klastrach.  Tabela \ref{tab:sredniediana} zawiera średnie wartości zmiennych, zaś Rysunki \ref{fig:boxdiana2} i \ref{fig:diana2credit} przedstawiają ich box-ploty.
<<echo=FALSE, eval=TRUE, results='asis', message=FALSE, warning=FALSE>>=
  srednie.diana2 <- dane1.numeric %>%
  mutate(Cluster = diana.k2) %>%
  group_by(Cluster) %>%
  summarise_all("mean")
srednie.diana2 <- data.frame(srednie.diana2)
library(stringr)
colnames(srednie.diana2) <- str_replace_all(colnames(srednie.diana2), "\\."," ")
print(xtable(srednie.diana2,caption="Średnie wartości zmiennych numerycznych w klastrach", label="tab:sredniediana",align = c("p{3cm}", "p{1.5cm}","p{1.5cm}","p{2cm}","p{2cm}","p{1.5cm}","p{2cm}","p{2cm}", "p{2cm}")),type="latex",table.placement = "H",include.rownames = F)
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  cluster.diana2 <- diana.k2
dane.diana2 <- data.frame(cbind(dane1.numeric, cluster.diana2))
colnames(dane.diana2) <- str_replace_all(colnames(dane.diana2), "\\."," ")
ggplot(data = melt(dane.diana2[,-2],id="cluster diana2"), aes(x=variable, y=value)) + geom_boxplot(aes(fill=factor(`cluster diana2`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-ploty zmiennych numerycznych z podziałem na klastry}\label{fig:boxdiana2}
\end{figure}
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ggplot(dane.diana2, aes(x=factor(`cluster diana2`), y=`Credit amount`))+
  geom_boxplot(aes(fill=factor(`cluster diana2`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-plot zmiennej Credit amount z podziałem na klastry}\label{fig:diana2credit}
\end{figure}

Na podstawie powyższych analiz nie widać znacznych różnic w wartościach zmiennych numerycznych w klastrach.
\section{Redukcja wymiaru}  
Przejdziemy teraz do redukcji wymiaru. Wykorzystamy w tym celu dwie różne metody: PCA i MDS.
\subsection{PCA}

Analizę składowych głównych możemy przeprowadzić jedynie dla zmiennych numerycznych. Ponownie więc wykorzystamy jedynie 7 zmiennych, których typ jest określony jako numeric. Z uwagi na duże różnice w wariancji poszczególnych zmiennych, zastosujemy PCA do przeskalowanych danych.
<<echo=FALSE, results='asis'>>=
  dane1.numeric-> data.pca
prcomp(data.pca, retx=T, center=T, scale.=T) -> data.after.pca

# print("Principal components:")
# print(data.after.pca$rotation)
# 
print(xtable(summary(data.after.pca), caption="Udział wyjaśnionej wariancji", label="tab:pca"),type="latex",table.placement = "H")
@
  
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  # Przeanalizujmy wariancję wyjaśnioną przez kolejne składowe główne
  variance <- (data.after.pca$sdev ^2)/sum(data.after.pca$sdev^2)
cumulative.variance <- cumsum(variance)
par(mfrow=c(1,2))
barplot(variance)
barplot(cumulative.variance)
abline(h=0.8, col="red")
grid(ny = 10)
@
  \caption{Scree plot}\label{fig:scree}
\end{figure}
Na Rysunku \ref{fig:scree} oraz w Tabeli \ref{tab:pca} widzimy, że pięć pierwszych składowych głównych wyjaśnia łącznie ponad $85\%$ całkowitej wariancji.

% <<echo=FALSE>>=
  % pc.comp = data.after.pca$x
% pc.comp[,1:5] -> dane.nowe
% kmeans(dane.nowe,2) -> pca.kmeans
% @
  
  % <<echo=FALSE,results='asis', warning=FALSE>>=
  % internal.validation11 <- clValid(dane.nowe,nClust=2:6,
                                     % clMethods = "kmeans",validation = "internal",maxitems=1000)
% #summary(internal.validation)
% mac11 <- as.data.frame(internal.validation11@measures)
% colnames(mac11) <- c("k=2","k=3","k=4","k=5", 'k=6')
% print(xtable(mac11,digits=3,caption="Wskaźniki wewnętrzne"),type="latex",table.placement = "H")
% print(xtable(optimalScores(internal.validation11),digits=3,caption="Najlepsze"),type="latex",table.placement = "H")
% @
  
% <<echo=FALSE>>=
  % etykietki.nowe.kmeans <- kmeans(dane.nowe,nstart=10,centers=5,iter.max=10)$cluster
% tabelka <- table(etykietki.nowe.kmeans,etykietki.rzeczywiste)
% matchClasses(tabelka)
% @
  
  \subsection{MDS}
Zastosujemy inną metodę redukcji wymiaru, a mianowicie skalowanie wielowymiarowe. Zaletą tej metody jest to, że możemy zastosować ją także do zmiennych mieszanych typów, wyznaczając macierz odmienności. Do oceny jakości MDS oraz wybrania wymiaru zastosujemy kryterium STRESS i diagram Sheparda. Ich zależność od wymiaru została przedstawiona odpowiednio  na Rysunkach \ref{fig:stress} i \ref{fig:shepard}.
<<echo=FALSE, warning=FALSE>>=
  # Wyznaczamy macierz niepodobieństwa/odmienności
  data.mds <- dane1
dissimilarities <- daisy(data.mds, stand=T)
dis.matrix <- as.matrix(dissimilarities)
@
  
  <<echo=FALSE>>=
  
  ### Kryterium STRESS i diagram Sheparda dla d=2
  
  # classical (metric) Multidimensional Scaling
  mds.k2 <- cmdscale(dis.matrix, k=2)
# obliczamy odległości euklidesowe w nowej przestrzeni
dist.mds.k2 <- dist(mds.k2, method="euclidean")
dist.mds.k2 <- as.matrix(dist.mds.k2)
@
  
  <<echo=FALSE>>=
  # kryterium STRESS
  dis.original <- dis.matrix
STRESS <- sum((dis.original-dist.mds.k2)^2)
@
  
% <<echo=FALSE, fig = TRUE>>=
  % # diagram Sheparda
% plot(dis.original,dist.mds.k2, main="Shepard diagram", cex=0.5, xlab="original distance", ylab="distance after MDS mapping")
% abline(coef=c(0,1), col="red", lty=2)# przekątna
% @
  
  <<echo=FALSE, fig=TRUE>>=
  ### Porównanie kryterium STRESS i wykresu Sheparda dla d=1,2,..., d.max
  
  d.max <- 12
stress.vec <- numeric(d.max)

for (d in 1:d.max)
{
  mds.k <- cmdscale(dis.matrix, k = d)
  dist.mds.k <- dist(mds.k, method="euclidean") # odległości w nowej przestrzeni
  dis.original <- dis.matrix
  dist.mds.k <- as.matrix(dist.mds.k)
  STRESS <- sum((dis.original-dist.mds.k)^2)
  stress.vec[d] <- STRESS
}
# X11()
# par(mfrow=c(4,3))
#  
# for (d in 1:d.max)
# {
#    mds.k <- cmdscale(dis.matrix, k = d)
#    dist.mds.k <- dist(mds.k, method="euclidean") # odległości w nowej przestrzeni
#    dis.original <- dis.matrix
#    dist.mds.k <- as.matrix(dist.mds.k)
#    STRESS <- sum((dis.original-dist.mds.k)^2)
# 
#    stress.vec[d] <- STRESS
# 
#    # Diagram Sheparda
#    plot(dis.original,dist.mds.k, main=paste0("Shepard diagram (d=",d,")"),
#         cex=0.5, xlab = "original distance",  ylab="distance after MDS")
#    abline(coef=c(0,1), col="red", lty=2)
#  }
# 
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  ###  STRESS vs. dimension
  plot(1:d.max, stress.vec, lwd=2, type="b", pch=19, xlab="dimension (d)", ylab="STRESS")
title("STRESS vs. dimension")
@
  \caption{Wartość kryterium STRESS w zależności od wymiaru}\label{fig:stress}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics{shepard12nostress.jpeg}
\caption{Diagramy Sheparda dla różnych wymiarów}\label{fig:shepard}
\end{figure}

Kierując się momentem, w którym wykres wartości STRESS zaczyna się wypłaszczać, oraz diagramami Sheparda, wybieramy $k=8$.

<<echo=FALSE>>=
  mds.k5 <- cmdscale(dis.matrix, k = 8)
dist.mds.k5 <- dist(mds.k5, method="euclidean") # odległości w nowej przestrzeni
dis.original <- dis.matrix
dist.mds.k5 <- as.matrix(dist.mds.k5)
@

\section{Klasyfikacja po MDS} 
Ponieważ analizowane dane są mieszanego typu, nie będziemy prowadzić dalszej analizy danych otrzymanych po PCA. Dane, które otrzymujemy po zastosowaniu MDS, wykorzystamy jako dane wejściowe w klasyfikacji. Podobnie jak w pierwszej części projektu, do danych dopasujemy następujące modele: regresji logistycznej, regresji logistycznej z metodą krokową, regresji logistycznej z kategoryzacją, liniowej analizy dyskryminacyjnej i kwadratowej analizy dyskryminacyjnej. Ponieważ znacznie lepsze były modele, które uczyniliśmy cost-sensitive za pomocą zmiany thresholdu (na $p=1/6$), tym razem nie będziemy już budować modeli cost-insensitive.  \\
W celu uzyskania wiarygodniejszych wyników, dane podzielimy na dwa zbiory: treningowy i testowy. Najpierw sprawdzimy działanie modeli na zbiorze treningowym, przeprowadzając w tym celu 5-krotną walidację krzyżową. Następnie, najlepsze modele zbudujemy dla całego zbioru treningowego i porównamy wyniki na zbiorze testowym. Ponieważ analizowane dane mają nierówny rozkład klas, zastosujemy tzw. stratified sampling.
W każdej iteracji walidacji wyznaczymy wskaźniki modelu takie jak: dokładność(ACC), czułość(TPR), specyficzność(TNR), F1 oraz średni koszt złej klasyfikacji(MMC). \\

Wyniki zostały przedstawione w Tabelach \ref{tab:cvregth_all}-\ref{tab:cvregth5}.
<<echo=FALSE, message=FALSE>>=
set.seed(41)
  library(MASS)
library(cluster)
dane <- read.table("german.data")
colnames(dane) <- c("Status of existing checking account","Duration in month",
                    "Credit history","Purpose","Credit amount","Savings account",
                    "Present employment since","Installment rate in percentage of disposable income",
                    "Personal status and sex","Other debtors","Present residence since",
                    "Property","Age in years","Other installment plans","Housing",
                    "Number of existing credits at this bank","Job","Number of people being liable to provide maintenance for",
                    "Telephone","foreign worker","creditability")
dane$creditability <- as.factor(ifelse(dane$creditability == 2, 1,0)) 
attach(dane)
dane1 <- dane[,1:20] #wyrzucamy creditability
typ <- c()
for (i in 1:dim(dane1)[2]){
  typ[i] <- class(dane1[,i])}
dane1.numeric <- dane1[,which(typ=="integer")]
@
  <<echo=FALSE,warning=FALSE>>=
  data.mds <- dane1
dissimilarities <- daisy(data.mds, stand=T)
dis.matrix <- as.matrix(dissimilarities)
mds.k5 <- cmdscale(dis.matrix, k = 8)
dist.mds.k5 <- dist(mds.k5, method="euclidean") # odległości w nowej przestrzeni
dis.original <- dis.matrix
dist.mds.k5 <- as.matrix(dist.mds.k5)
@
  <<echo=FALSE, message=FALSE>>=
  creditability <- dane$creditability
dane.nowe1 <- as.data.frame(cbind(mds.k5, creditability))
dane.nowe1$creditability <- as.factor(ifelse(dane.nowe1$creditability == 2, 1,0))
attach(dane.nowe1)
@
  <<echo=FALSE, warning=FALSE, message=FALSE>>=
  library(dismo)
#library(fifer)
dane_losowo0<-dane.nowe1[sample(nrow(dane.nowe1)),]
#folds <- cut(seq(1,nrow(dane_losowo)),breaks=5,labels=FALSE)
folds0 <- kfold(dane_losowo0, 4, creditability)
indeksy_test_final <- which(folds0==4,arr.ind=TRUE)
test_final <- dane_losowo0[indeksy_test_final, ]
dane_losowo<- dane_losowo0[-indeksy_test_final, ]
folds <- kfold(dane_losowo, 5, dane_losowo$creditability)
#folds <- stratified(dane_losowo, creditability, 0.2)
@
  
  <<echo=FALSE, eval=FALSE>>=
  print((sum(test_final$creditability==1))/length(test_final$creditability))
@
  
  <<echo=FALSE, eval=FALSE>>=
  for (i in 1:5){
    dane_losowo[which(folds==i,arr.ind=TRUE),] -> x
    print ((sum(x$creditability==1))/length(x$creditability))
  }
@
  
  <<echo=FALSE>>=
  # poniższa funkcja wylicza ACC itd dla danej walidacji 
  wskazniki <- function(klasy, test){ # klasy - wektor przewidywanych klas dla zbioru testowego, test - zbiór testowy
    vec <- c()
    for (k in 1:length(klasy))
    {if (klasy[k]==0&test$creditability[k]==0) {vec[k]="TN"} else {if (klasy[k]==1&test$creditability[k]==0) {vec[k]="FP"} else{if (klasy[k]==0&test$creditability[k]==1)
    {vec[k]="FN"} else {vec[k]="TP"}}}}
    N <- sum(sum(vec=="TN")+sum(vec=="FP"))
    P <- sum(sum(vec=="FN")+sum(vec=="TP"))
    Ng <- sum(sum(vec=="TN")+sum(vec=="FN"))
    Pg <- sum(sum(vec=="FP")+sum(vec=="TP"))
    TPR <- sum(vec=="TP")/P # czulosc
    TNR <- sum(vec=="TN")/N # specyficznosc
    FPR <- sum(vec=="FP")/N
    blad <- mean(klasy != test$creditability)
    ACC <- 1-blad
    F1 <- 2*TPR*FPR/(TPR+FPR)
    return(c(ACC, TPR, TNR, F1))
  }
@
  
  <<echo=FALSE, eval = TRUE>>=
  #macierz kosztów
  cost_matrix <- matrix(nrow=2, ncol=2, c(0,1,5,0),byrow=TRUE)
colnames(cost_matrix) <- c("predicted good", "predicted bad")
rownames(cost_matrix) <- c("actual good", "actual bad")

#threshold p*
th = cost_matrix[1,2]/ (cost_matrix[2,1] + cost_matrix[1,2])


# mean misclassification cost
mmc <- function(klasy, test, cost_matrix){ #klasy - przewidywane, test - zbiór testowy
  c01 <- cost_matrix[2,1]
  c10 <- cost_matrix[1,2]
  w <- c() # tworzymy wektor wag
  for (i in (1:length(klasy))){
    if (test[i,9]==0) {w[i] = c10}
    else {w[i] = c01}
  }
  return((sum(as.numeric(klasy!=test[,9])*w))/length(klasy))
}

@
  <<echo=FALSE,warning=FALSE, fig=TRUE,message=FALSE>>=
  library(pROC)
mat_lr_th <- matrix(nrow=5, ncol = 5) # dla thresholdu


for(i in 1:5){
  indeksy_test <- which(folds==i,arr.ind=TRUE)
  test <- dane_losowo[indeksy_test, ]
  train <- dane_losowo[-indeksy_test, ]
  model_rl <- glm(formula = creditability~., family = binomial(link='logit'), data = train)
  prob <- predict(model_rl,test,type='response')
  # zastosowanie thresholdu
  klasy_th <- ifelse(prob > th,1,0)
  mat_lr_th[i,] <- c(wskazniki(klasy_th, test), mmc(klasy_th, test, cost_matrix)) 
}
@
  
  <<echo=FALSE>>=
  colMeans(mat_lr_th) -> v_lr_th  
@  
  
  
  <<echo=FALSE, eval=TRUE, results='asis'>>=
  mat_lr_th <- rbind(mat_lr_th,v_lr_th)
colnames(mat_lr_th) <- c("ACC","TPR","TNR","F1", "MMC")
rownames(mat_lr_th) <- c("1", "2", "3", "4", "5", "średnia")
print(xtable(mat_lr_th,caption="Tabela wskaźników dla 5-fold cross-validation w modelu regresji logistycznej z p=1/6 po MDS" , label="tab:cvregth_all"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  <<echo=FALSE, warning=FALSE,fig=TRUE,message=FALSE>>=
  library(woeBinning)
mat2_th <- matrix(nrow=5, ncol = 5)

for(i in 1:5){
  indeksy_test <- which(folds==i,arr.ind=TRUE)
  test <- dane_losowo[indeksy_test, ]
  train <- dane_losowo[-indeksy_test, ]
  woe.binning(train,'creditability',train) -> iv
  iv[which(iv[,3]>=0.02),] -> ivwieksze
  laczenie <- woe.binning.deploy(train, ivwieksze,min.iv.total=0.02)
  testlaczenie <- woe.binning.deploy(test,ivwieksze,min.iv.total=0.02,add.woe.or.dum.var='woe')
  laczeniebin <- cbind(laczenie[ , grepl( "binned" , names( laczenie ) ) ],laczenie$creditability)
  regfitbin <- glm(laczeniebin$`laczenie$creditability`~.,family=binomial(link=logit),data=laczeniebin)
  regfitbin1 <- step(regfitbin, trace=0)
  prob <- predict(regfitbin1, testlaczenie, type='response')
  # zastosowanie thresholdu
  klasy_th <- ifelse(prob > th,1,0)
  mat2_th[i,] <- c(wskazniki(klasy_th, test), mmc(klasy_th, test, cost_matrix)) 
}
@
  
  <<echo=FALSE>>=
  colMeans(mat2_th) -> v2_th
@
  
  
  <<echo=FALSE, eval=TRUE, results='asis'>>=
  mat2_th <- rbind(mat2_th, v2_th)
colnames(mat2_th) <- c("ACC","TPR","TNR","F1", "MMC")
rownames(mat2_th) <- c("1", "2", "3", "4", "5", "średnia")
print(xtable(mat2_th,caption="Tabela wskaźników dla 5-fold cross-validation w modelu regresji logistycznej z kategoryzacją  z p=1/6 po MDS", label="tab:cvregth2"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  
  
  <<echo=FALSE,warning=FALSE, fig=TRUE,message=FALSE>>=
  mat_th <- matrix(nrow=5, ncol = 5) # dla thresholdu


for(i in 1:5){
  indeksy_test <- which(folds==i,arr.ind=TRUE)
  test <- dane_losowo[indeksy_test, ]
  train <- dane_losowo[-indeksy_test, ]
  model <- glm(formula = creditability~., family = binomial(link='logit'), data = train)
  model_rl <- step(model,trace=0)
  prob <- predict(model_rl,test,type='response')
  
  # zastosowanie thresholdu
  klasy_th <- ifelse(prob > th,1,0)
  mat_th[i,] <- c(wskazniki(klasy_th, test), mmc(klasy_th, test, cost_matrix)) 
}
@
  
  <<echo=FALSE>>=
  colMeans(mat_th) -> v_th
@
  
  
  <<echo=FALSE, eval=TRUE, results='asis'>>=
  mat_th<-rbind(mat_th, v_th)
colnames(mat_th) <- c("ACC","TPR","TNR","F1", "MMC")
rownames(mat_th) <- c("1", "2", "3", "4", "5", "średnia")
print(xtable(mat_th,caption="Tabela wskaźników dla 5-fold cross-validation w modelu regresji logistycznej z metodą krokową z p=1/6 po MDS", label="tab:cvregth"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  
  <<echo=FALSE,fig=TRUE,message=FALSE>>=
  library(MASS)
mat4_th <- matrix(nrow=5, ncol = 5)

for(i in 1:5){
  indeksy_test <- which(folds==i,arr.ind=TRUE)
  test <- dane_losowo[indeksy_test, ]
  train <- dane_losowo[-indeksy_test, ]
  ldafit <- lda(creditability ~ ., data = train)
  lda.pred <- predict(ldafit, newdata=test)
  prob <- lda.pred$posterior[,2]
  
  # zastosowanie thresholdu
  klasy_th <- ifelse(prob > th,1,0)
  mat4_th[i,] <- c(wskazniki(klasy_th, test), mmc(klasy_th, test, cost_matrix)) 
}
@
  
  <<echo=FALSE>>=
  colMeans(mat4_th) -> v4_th
@
  
  
  <<echo=FALSE, eval=TRUE, results='asis'>>=
  mat4_th <- rbind(mat4_th, v4_th)
colnames(mat4_th) <- c("ACC","TPR","TNR","F1", "MMC")
rownames(mat4_th) <- c("1", "2", "3", "4", "5", "średnia")
print(xtable(mat4_th,caption="Tabela wskaźników dla 5-fold cross-validation w LDA z p=1/6 po MDS", label="tab:cvregth4"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  
  <<echo=FALSE,fig=TRUE,message=FALSE>>=
  mat5_th <- matrix(nrow=5, ncol = 5)

for(i in 1:5){
  indeksy_test <- which(folds==i,arr.ind=TRUE)
  test <- dane_losowo[indeksy_test, ]
  train <- dane_losowo[-indeksy_test, ]
  qdafit <- qda(creditability ~ ., data = train)
  qda.pred <- predict(qdafit, newdata=test)
  prob <- qda.pred$posterior[,2]
  
  # zastosowanie thresholdu
  klasy_th <- ifelse(prob > th,1,0)
  mat5_th[i,] <- c(wskazniki(klasy_th, test), mmc(klasy_th, test, cost_matrix)) 
}
@
  
  <<echo=FALSE>>=
  colMeans(mat5_th) -> v5_th
@
  
  
  <<echo=FALSE, eval=TRUE, results='asis'>>=
  mat5_th <-rbind(mat5_th, v5_th)  
colnames(mat5_th) <- c("ACC","TPR","TNR","F1", "MMC")
rownames(mat5_th) <- c("1", "2", "3", "4", "5", "średnia")
print(xtable(mat5_th,caption="Tabela wskaźników dla 5-fold cross-validation w modelu QDA z p=1/6 po MDS", label="tab:cvregth5"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  
  Wszystkie modele rokują dość dobrze. W każdym z przypadków średnia wartość $F1$ jest wyższa niż 0.5. Dla żadnej z metod nie uzyskujemy MMC wyższego niż 0.6. Także czułość jest na wysokim poziomie - dla każdego z modeli powyżej 0.8.  \\Teraz wszystkie modele zbudujemy ponownie, tym razem dla całego zbioru treningowego i porównamy ich skuteczność na zbiorze testowym. Aby skontrolować, czy modele nie są przeuczone, sprawdzimy również jak wygląda ich predykcja na zbiorze treningowym. Wyniki znajdują się w Tabelach \ref{tab:rlfinal}-\ref{tab:qdafinal}.


<<echo=FALSE>>=
  model2_RL <- glm(formula = creditability~., family = binomial(link='logit'), data = dane_losowo)
@
  
  <<echo=FALSE,eval=FALSE>>=
  print(model2_RL)
summary(model2_RL)
@
  <<echo=FALSE,eval=FALSE>>=
  #  współczynniki modelu
  (wspolczynniki <- coefficients(model2_RL))
@
  
  <<echo=FALSE>>=
  predykcja_LR_test <- predict(model2_RL, test_final , type = "response")
# klasy_LR <- ifelse(predykcja_LR_test > 0.5,1,0)
# oceny_LR <- c(wskazniki(klasy_LR, test_final), mmc(klasy_LR, test_final, cost_matrix))
klasy_th_LR <- ifelse(predykcja_LR_test > th,1,0)
oceny_th_LR <- c(wskazniki(klasy_th_LR, test_final), mmc(klasy_th_LR, test_final, cost_matrix)) 
predykcja_LR_train <- predict(model2_RL,dane_losowo,  type="response")  
# klasy_LR_train <- ifelse(predykcja_LR_train > 0.5,1,0)
# oceny_LR_train <- c(wskazniki(klasy_LR_train, dane_losowo), mmc(klasy_LR_train, dane_losowo, cost_matrix))
klasy_th_LR_train <- ifelse(predykcja_LR_train > th,1,0)
oceny_th_LR_train <- c(wskazniki(klasy_th_LR_train, dane_losowo), mmc(klasy_th_LR_train, dane_losowo, cost_matrix))
@
  <<echo=FALSE, results = 'asis'>>=
  # r1 <- oceny_LR
  r2 <- oceny_th_LR
# r3 <- oceny_LR_train
r4 <- oceny_th_LR_train
macierzwskazniki <- matrix(nrow=4,ncol=5)
macierzwskazniki <- rbind(r2,r4)
colnames(macierzwskazniki) <- c("ACC","TPR","TNR","F1","MMC")
# rownames(macierzwskazniki) <- c("p=0.5 test" ,"p=1/6 test","p=0.5 train","p=1/6 train")

rownames(macierzwskazniki) <- c("test", "train")
print(xtable(macierzwskazniki,caption="Tabela wskaźników dla LR z p=1/6 po MDS", label="tab:rlfinal"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  
  <<echo=FALSE>>=
  woe.binning(dane_losowo,'creditability',dane_losowo) -> iv
iv[which(iv[,3]>=0.02),] -> ivwieksze
@
  
  <<echo=FALSE, fig=TRUE>>=
  woe.binning.plot(ivwieksze)
@
  
  <<echo=FALSE, fig=TRUE, message=FALSE>>=
  laczenie <- woe.binning.deploy(dane_losowo, ivwieksze,min.iv.total=0.02)
testlaczenie <- woe.binning.deploy(test_final,ivwieksze,min.iv.total=0.02,add.woe.or.dum.var='woe')
trainlaczenie <-  woe.binning.deploy(dane_losowo,ivwieksze,min.iv.total=0.02,add.woe.or.dum.var='woe')
laczeniebin <- cbind(laczenie[ , grepl( "binned" , names( laczenie ) ) ],laczenie$creditability)
regfitbin <- glm(laczeniebin$`laczenie$creditability`~.,family=binomial(link=logit),data=laczeniebin)
regfitbin1 <- step(regfitbin, trace=0)
prob <- predict(regfitbin1, testlaczenie, type='response')
predykcja_LR_bin_test <- prob
# roc <- roc(testlaczenie$creditability~prob)
# plot(roc,lwd = 1, col = 'blue')
klasy <- ifelse(prob > 0.5,1,0)
klasy_LR_bin <- klasy
# oceny_LR_bin <- c(wskazniki(klasy_LR_bin, testlaczenie), mmc(klasy_LR_bin, testlaczenie, cost_matrix))
klasy_th <- ifelse(prob > th,1,0)
klasy_th_LR_bin <- klasy_th
oceny_th_LR_bin <- c(wskazniki(klasy_th_LR_bin, testlaczenie), mmc(klasy_th_LR_bin, testlaczenie, cost_matrix)) 
prob2 <- predict(regfitbin1, trainlaczenie, type='response')
predykcja_LR_train_bin  <- prob2
klasy_train <- ifelse(prob2 > 0.5,1,0)
klasy_LR_train_bin <- klasy_train
# oceny_LR_train_bin <- c(wskazniki(klasy_LR_train_bin, trainlaczenie), mmc(klasy_LR_train_bin, trainlaczenie, cost_matrix)) 
klasy_th_LR_train_bin <- ifelse(predykcja_LR_train_bin > th,1,0)
oceny_th_LR_train_bin <- c(wskazniki(klasy_th_LR_train_bin, trainlaczenie), mmc(klasy_th_LR_train_bin, trainlaczenie, cost_matrix))

@
  
  <<echo=FALSE, results = 'asis'>>=
  # r1bin <- oceny_LR_bin
  r2bin <- oceny_th_LR_bin
# r3bin <- oceny_LR_train_bin
r4bin <- oceny_th_LR_train_bin
macierzwskazniki_bin <- matrix(nrow=4,ncol=5)
macierzwskazniki_bin <- rbind(r2bin,r4bin)
colnames(macierzwskazniki_bin) <- c("ACC","TPR","TNR","F1","MMC")
# rownames(macierzwskazniki_bin) <- c("p=0.5 test" ,"p=1/6 test","p=0.5 train","p=1/6 train")
rownames(macierzwskazniki_bin) <- c("test", "train")
print(xtable(macierzwskazniki_bin,caption="Tabela wskaźników dla LR(category) z p=1/6 po MDS", label="tab:rlfinalbin"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  
  <<echo=FALSE>>=
  model30_RL <- glm(formula = creditability~., family = binomial(link='logit'), data = dane_losowo)
model3_RL <- step(model30_RL, trace=0) 
@
  <<echo=FALSE,eval=FALSE>>=
  print(model3_RL)
summary(model3_RL)
@
  <<echo=FALSE>>=
  predykcja_LR_test3 <- predict(model3_RL, test_final , type = "response")
klasy_th_LR3 <- ifelse(predykcja_LR_test3 > th,1,0)
oceny_th_LR3 <- c(wskazniki(klasy_th_LR3, test_final), mmc(klasy_th_LR3, test_final, cost_matrix)) 
predykcja_LR_train3 <- predict(model3_RL,dane_losowo,  type="response")  
klasy_th_LR_train3 <- ifelse(predykcja_LR_train3 > th,1,0)
oceny_th_LR_train3 <- c(wskazniki(klasy_th_LR_train3, dane_losowo), mmc(klasy_th_LR_train3, dane_losowo, cost_matrix))
@
  <<echo=FALSE, results = 'asis'>>=
  r23 <- oceny_th_LR3
r43 <- oceny_th_LR_train3
macierzwskazniki3 <- matrix(nrow=2,ncol=5)
macierzwskazniki3 <- rbind(r23,r43)
colnames(macierzwskazniki3) <- c("ACC","TPR","TNR","F1","MMC")
rownames(macierzwskazniki3) <- c("test","train")
print(xtable(macierzwskazniki3,caption="Tabela wskaźników dla LR(step) z p=1/6 po MDS", label="tab:rlfinal3"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  
  <<echo=FALSE>>=
  model_lda <- lda(creditability ~., data = dane_losowo)
@
  
  <<echo=FALSE>>=
  pred_LDA_test <- predict(model_lda, newdata=test_final)
predykcja_LDA_test <- pred_LDA_test$posterior[,2]
pred_LDA_train <- predict(model_lda,newdata=dane_losowo)
predykcja_LDA_train <- pred_LDA_train$posterior[,2]
# klasy_LDA <- ifelse(predykcja_LDA_test > 0.5,1,0)
# oceny_LDA <- c(wskazniki(klasy_LDA, test_final), mmc(klasy_LDA, test_final, cost_matrix))
klasy_th_LDA <- ifelse(predykcja_LDA_test > th,1,0)
oceny_th_LDA <- c(wskazniki(klasy_th_LDA, test_final), mmc(klasy_th_LDA, test_final, cost_matrix))
# klasy_LDA_train <- ifelse(predykcja_LDA_train > 0.5,1,0)
# oceny_LDA_train <- c(wskazniki(klasy_LDA_train, dane_losowo), mmc(klasy_LDA_train, dane_losowo, cost_matrix))
klasy_th_LDA_train <- ifelse(predykcja_LDA_train > th,1,0)
oceny_th_LDA_train <- c(wskazniki(klasy_th_LDA_train, dane_losowo), mmc(klasy_th_LDA_train, dane_losowo, cost_matrix))
@
  
  <<echo=FALSE, results = 'asis'>>=
  # r1_lda <- oceny_LDA
  r2_lda <- oceny_th_LDA
# r3_lda <- oceny_LDA_train
r4_lda <- oceny_th_LDA_train
macierzwskazniki_lda <- matrix(nrow=2,ncol=5)
macierzwskazniki_lda <- rbind(r2_lda,r4_lda)
colnames(macierzwskazniki_lda) <- c("ACC","TPR","TNR","F1","MMC")
rownames(macierzwskazniki_lda) <- c("test","train")
print(xtable(macierzwskazniki_lda,caption="Tabela wskaźników dla LDA z p=1/6 po MDS", label="tab:ldafinal"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  
  <<echo=FALSE>>=
  model_qda <- qda(creditability~., data = dane_losowo)
@
  
  <<echo=FALSE>>=
  pred_QDA_test <- predict(model_qda, newdata=test_final)
predykcja_QDA_test <- pred_QDA_test$posterior[,2]
pred_QDA_train <- predict(model_qda,newdata=dane_losowo)
predykcja_QDA_train <- pred_QDA_train$posterior[,2]
# klasy_QDA <- ifelse(predykcja_QDA_test > 0.5,1,0)
# oceny_QDA <- c(wskazniki(klasy_QDA, test_final), mmc(klasy_QDA, test_final, cost_matrix))
klasy_th_QDA <- ifelse(predykcja_QDA_test > th,1,0)
oceny_th_QDA <- c(wskazniki(klasy_th_QDA, test_final), mmc(klasy_th_QDA, test_final, cost_matrix))
# klasy_QDA_train <- ifelse(predykcja_QDA_train > 0.5,1,0)
# oceny_QDA_train <- c(wskazniki(klasy_QDA_train, dane_losowo), mmc(klasy_QDA_train, dane_losowo, cost_matrix))
klasy_th_QDA_train <- ifelse(predykcja_QDA_train > th,1,0)
oceny_th_QDA_train <- c(wskazniki(klasy_th_QDA_train, dane_losowo), mmc(klasy_th_QDA_train, dane_losowo, cost_matrix))
@
  <<echo=FALSE, results = 'asis'>>=
  # r1_qda <- oceny_QDA
  r2_qda <- oceny_th_QDA
# r3_qda <- oceny_QDA_train
r4_qda <- oceny_th_QDA_train
macierzwskazniki_qda <- matrix(nrow=4,ncol=5)
macierzwskazniki_qda <- rbind(r2_qda,r4_qda)
colnames(macierzwskazniki_qda) <- c("ACC","TPR","TNR","F1","MMC")
rownames(macierzwskazniki_qda) <- c("test", "train")
print(xtable(macierzwskazniki_qda,caption="Tabela wskaźników dla QDA z p=1/6 po MDS", label="tab:qdafinal"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  Analizując wyniki zawarte w Tabelach \ref{tab:rlfinal}-\ref{tab:qdafinal} nie widzimy znacznych różnic pomiędzy wartościami wskaźników dla zbioru testowego oraz treningowego. Oznacza to, że modele nie są przeuczone.\\
Zbiorcze porównanie wyników na zbiorze testowym przedstawia Tabela \ref{tab:porfinal}.

<<echo=FALSE, results = 'asis'>>= 
  final <- rbind(r2, r2bin,  r23,  r2_lda,  r2_qda)
colnames(final) <- c("ACC","TPR","TNR","F1", "MMC")
rownames(final) <- c("LR", "LR(category)","LR(step)", "LDA","QDA")
print(xtable(final,caption="Tabela wskaźników dla wszystkich modeli na zbiorze testowym z p =1/6 po MDS", label="tab:porfinal"),sanitize.rownames.function=function(x){x}, type="latex",table.placement = "H")
@
  
  Wskaźniki F1 i MMC są bardzo zbliżone dla wszystkich metod. Najniższy MMC otrzymujemy dla regresji logistycznej z kategoryzacją - wynosi on 0.54. Najwyższą wartość F1, równą 0.67, uzyskujemy dla liniowej analizy dyskryminacyjnej. \\
Wyniki, które otrzymaliśmy w pierwszej części projektu, dla danych bez zastosowania redukcji wymiaru, znajdują się w Tabeli \ref{tab:porfinalstare}.

\begin{table}[H]
\centering
\begin{tabular}{rrrrrr}
\hline
& ACC & TPR & TNR & F1 & MMC \\ 
\hline
LR & 0.61 & 0.77 & 0.53 & 0.58 & 0.69 \\ 
LR(category) & 0.65 & 0.87 & 0.54 & 0.60 & 0.53 \\ 
LR(step) & 0.66 & 0.81 & 0.59 & 0.55 & 0.60 \\ 
LDA & 0.61 & 0.86 & 0.49 & 0.64 & 0.58 \\ 
QDA & 0.67 & 0.77 & 0.62 & 0.51 & 0.64 \\ 
\hline
\end{tabular}
\caption{Tabela wskaźników dla wszystkich modeli na zbiorze testowym z p =1/6} 
\label{tab:porfinalstare}
\end{table}

Porównując dwie powyższe tabele widzimy, że po zastosowaniu MDS poprawił się wskaźnik F1 w przypadku wszystkich modeli klasyfikacyjnych. W większości przypadków mamy też niższe wartości MMC. Nieznacznie wyższą wartość otrzymujemy dla modelu regresji liniowej z kategoryzacją. Po zastosowaniu MDS wynosi on 0.54, zaś przed redukcją wymiaru był równy 0.53. Z modeli budowanych przed MDS najwyższe F1 miała liniowa analiza dyskryminacyjna, zaś najniższy MMC - regresja liniowa z kategoryzacją. Wśród modeli stworzonych po MDS jest tak samo.

\section{Klasteryzacja po MDS}
Przeprowadzimy analizę skupień dla danych po zastosowaniu MDS. Mając na uwadze to, że w tym przypadku wartości zmiennych są numeryczne, ocenę jakości grupowania przedstawimy na sam koniec, uwzględniając wszystkie z omawianych algorytmów oraz różne wartości k.
\subsection{k-means}
Sprawdzimy jedynie jakie wyniki otrzymujemy dla k=2. Przeanalizujemy wartości zmiennych po MDS w zależności od przypisanego klastra. Tabela \ref{tab:sredniekmeansmds} zawiera średnie wartości zmiennych, zaś Rysunek \ref{fig:boxkmeans2mds} przedstawia ich box-ploty.

<<echo=FALSE, eval=TRUE, results='asis', message=FALSE, warning=FALSE>>=
set.seed(123)  
library(dplyr)
kmeans2.mds <- kmeans(data.frame(mds.k5), centers=2,iter.max=10, nstart=10)
etykietki.kmeans2.mds <- kmeans2.mds$cluster
srednie.kmeans2.mds <- data.frame(mds.k5) %>%
  mutate(Cluster = etykietki.kmeans2.mds) %>%
  group_by(Cluster) %>%
  summarise_all("mean")
srednie.kmeans2.mds <- data.frame(srednie.kmeans2.mds)
library(stringr)
# colnames(srednie.kmeans2.mds) <- str_replace_all(colnames(srednie.kmeans2.mds), "\\."," ")
colnames(srednie.kmeans2.mds) <- c('Cluster', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8')
print(xtable(srednie.kmeans2.mds,caption="Średnie wartości zmiennych po MDS w klastrach", label="tab:sredniekmeansmds",align = c("p{3cm}", "p{1.75cm}","p{1.75cm}","p{1.75cm}","p{1.75cm}","p{1.75cm}","p{1.75cm}","p{1.75cm}", "p{1.75cm}", "p{1.75cm}")),type="latex",table.placement = "H",include.rownames = F)
@

\begin{figure}[H]
<<echo=FALSE, fig=TRUE, message=FALSE, warning=FALSE>>=
  library(reshape)
library(ggplot2)
cluster.kmeans2.mds <- etykietki.kmeans2.mds
dane.kmeans2.mds <- data.frame(cbind(mds.k5, cluster.kmeans2.mds))
colnames(dane.kmeans2.mds) <- str_replace_all(colnames(dane.kmeans2.mds), "\\."," ")
ggplot(data = melt(dane.kmeans2.mds[,-2],id="cluster kmeans2 mds"), aes(x=variable, y=value)) + geom_boxplot(aes(fill=factor(`cluster kmeans2 mds`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-ploty zmiennych po MDS z podziałem na klastry}\label{fig:boxkmeans2mds}
\end{figure}

Z tabeli możemy odczytać, że największą różnicę w średnich wartościach zmiennych w klastrach mamy dla V1. Dla pozostałych zmiennych różnice tę są mniejsze niż 0.1. Potwierdzenie wyników z tabeli otrzymujemy na box-plotach.  Widzimy, że zakresy przyjmowane przez zmienną V1 są wyraźnie różne w obu klastrach (w jednym są znacznie wyższe niż w drugim). Podobną sytuację obserwowaliśmy przed zastosowaniem MDS. Wówczas największe różnice miały miejsce dla zmiennych Credit Amount i Durarion in Month.

<<echo=FALSE, results='asis', warning=FALSE, message=FALSE>>=
  library(e1071)
etykietki.rzeczywiste <- dane$creditability
etykietki.2means.mds <- kmeans(mds.k5,nstart=10,centers=2,iter.max=10)$cluster
tabelka.m <- table(etykietki.2means.mds,etykietki.rzeczywiste)
print(xtable(tabelka.m, label="tab:ktablemds", caption="Macierz kontyngencji - k-means"), type="latex", table.placement="H", include.rownames=TRUE)
@
  Z powyższej tabeli możemy odczytać, że w pierwszym klastrze jest 591 obserwacji, w drugim natomiast 409.
<<echo=FALSE>>=
  matchClasses(tabelka.m, method='exact')
@
  Wynik, który otrzymaliśmy przy użyciu funkcji matchClasses jest niższy od tego, który uzyskaliśmy dla algorytmu 2-means dla danych przeskalowanych, przed redukcją wymiaru.
\subsection{PAM}
Sprawdzimy jedynie jakie wyniki otrzymujemy dla k=2. Przeanalizujemy wartości zmiennych po MDS w zależności od przypisanego klastra. Tabela \ref{tab:sredniepammds} zawiera średnie wartości zmiennych, zaś Rysunek \ref{fig:boxpam2mds} przedstawia ich box-ploty.

<<echo=FALSE, eval=TRUE, results='asis', message=FALSE, warning=FALSE>>=
  library(dplyr)
pam2.mds <- pam(data.frame(mds.k5), diss=FALSE, k=2)
etykietki.pam2.mds <- pam2.mds$clustering
srednie.pam2.mds <- data.frame(mds.k5) %>%
  mutate(Cluster = etykietki.pam2.mds) %>%
  group_by(Cluster) %>%
  summarise_all("mean")
srednie.pam2.mds <- data.frame(srednie.pam2.mds)
library(stringr)
# colnames(srednie.pam2.mds) <- str_replace_all(colnames(srednie.pam2.mds), "\\."," ")
colnames(srednie.pam2.mds) <- c('Cluster', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8')
print(xtable(srednie.pam2.mds,caption="Średnie wartości zmiennych po MDS w klastrach", label="tab:sredniepammds",align = c("p{3cm}", "p{1.75cm}","p{1.75cm}","p{1.75cm}","p{1.75cm}","p{1.75cm}","p{1.75cm}","p{1.75cm}", "p{1.75cm}","p{1.75cm}")),type="latex",table.placement = "H",include.rownames = F)
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE, message=FALSE, warning=FALSE>>=
  library(reshape)
library(ggplot2)
cluster.pam2.mds <- etykietki.pam2.mds
dane.pam2.mds <- data.frame(cbind(mds.k5, cluster.pam2.mds))
colnames(dane.pam2.mds) <- str_replace_all(colnames(dane.pam2.mds), "\\."," ")
ggplot(data = melt(dane.pam2.mds[,-2],id="cluster pam2 mds"), aes(x=variable, y=value)) + geom_boxplot(aes(fill=factor(`cluster pam2 mds`)))+
  coord_flip()+
  theme(legend.position="none")
@
  \caption{Box-ploty zmiennych po MDS z podziałem na klastry}\label{fig:boxpam2mds}
\end{figure}

Podobnie jak w przypadku algorytmu k-means, największe różnice w średnich wartościach zmiennych otrzymujemy dla V1. Jednak teraz wartości tej zmiennej nie różnią się tak wyraźnie. Zakresy wartości pozostałych zmiennych niewiele różnią się pomiędzy klastrami. Przed zastosowaniem redukcji wymiaru również nie było znacznych różnic w zakresie wartości zmiennych w poszczególnych klastrach.


<<echo=FALSE, results='asis', warning=FALSE, message=FALSE>>=
  library(e1071)
etykietki.rzeczywiste <- dane$creditability
etykietki.2means.mds <- pam(mds.k5,diss=FALSE,k=2)$clustering
tabelka.m2 <- table(etykietki.2means.mds,etykietki.rzeczywiste)
print(xtable(tabelka.m2, label="tab:ptablemds", caption="Macierz kontyngencji - PAM"), type="latex", table.placement="H", include.rownames=TRUE)
@
Do pierwszego klastra zaliczono 490 obserwacji, zaś do drugiego 510.
  <<echo=FALSE>>=
  matchClasses(tabelka.m2, method='exact')
@
Procent zgodnych klas rzeczywistych i przypisanych wynosi $56,4\%$.
  \subsection{AGNES}
Zastosujemy teraz metodę AGNES dla różnych metod łączenia klastrów z $k=2$.
\subsubsection{average linkage}
Rysunek \ref{fig:agnesmdsavg} przedstawia dendrogram, zaś na Rysunku \ref{fig:agnesmdsavg2} zaznaczyliśmy klasy rzeczywiste na dendrogramie.
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  agnes.mds.avg <- agnes(x=mds.k5,diss=FALSE,method="average")
plot(agnes.mds.avg,which.plots=2,main="AGNES: average linkage")
agnes.mds.avg.k2 <- cutree(agnes.mds.avg,k=2) 
@
  \caption{Dendrogram - AGNES - average linkage}\label{fig:agnesmdsavg}
\end{figure}
<<echo=FALSE>>=
  # kolorowanie liści dendrogramu
  # kolory == rzeczywiste klasy 
  etykietki.kolory <- as.numeric(dane$creditability) #1 lub 2
kolory.nazwy     <- levels(as.factor(dane$creditability))

# pomocnicza funkcja do kolorowania liści w dendrogramie
col.labels <<- function(node) 
{  
  if(is.leaf(node)) 
  {
    a <- attributes(node)
    label <- attr(node, "label")
    attr(node, "nodePar") <-  c(a$nodePar, list(lab.col = etykietki.kolory[label]))
  }      
  
  return(node)
}
@
  
  \begin{figure}[H]
<<echo=FALSE,fig=TRUE>>=
  hc.kol.mds.avg <- dendrapply(as.dendrogram(agnes.mds.avg), col.labels)
# rysuj dendrogram
par(cex=0.7)
plot(hc.kol.mds.avg)
legend("topright", legend=kolory.nazwy, col=1:3, pch=15, bg="azure2", cex=1.5)
@
  \caption{Dendrogram - AGNES - average linkage z etykietkami rzeczywistymi}\label{fig:agnesmdsavg2}
\end{figure}

Poniżej przedstawiamy macierz kontyngencji dla $k=2$.
<<echo=FALSE,results='asis'>>=
  tabelka.agnes.mds.avg2<- table(agnes.mds.avg.k2,etykietki.rzeczywiste)
print(xtable(tabelka.agnes.mds.avg2, caption="Macierz kontyngencji - AGNES - average linkage", label="tab:etykagnesavg2"),type="latex",table.placement = "H",include.rownames = T)
@
  <<echo=FALSE>>=
  matchClasses(tabelka.agnes.mds.avg2, method='exact')
@
  Podobnie jak przypadku klasteryzacji przed zastosowaniem MDS, jeden z klastrów jest mało liczny. Tym razem jest w nim zaledwie 13 obserwacji.
\subsubsection{single linkage}
Podobnie jak poprzednio, rysujemy dendrogram. Znajduje się on na Rysunku \ref{fig:agnesmdssingle}. Z kolei Rysunek \ref{fig:agnesmdssingle2} przedstawia dendrogram z zaznaczonymi klasami rzeczywistymi.
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  agnes.mds.single <- agnes(x=mds.k5,diss=FALSE,method="single")
plot(agnes.mds.single,which.plots=2,main="AGNES: single linkage")
agnes.mds.single.k2 <- cutree(agnes.mds.single,k=2) 
@
  \caption{Dendrogram - AGNES - single linkage}\label{fig:agnesmdssingle}
\end{figure}

\begin{figure}[H]
<<echo=FALSE,fig=TRUE>>=
  hc.kol.mds.single <- dendrapply(as.dendrogram(agnes.mds.single), col.labels)
# rysuj dendrogram
par(cex=0.7)
plot(hc.kol.mds.single)
legend("topright", legend=kolory.nazwy, col=1:3, pch=15, bg="azure2", cex=1.5)
@
  \caption{Dendrogram - AGNES - single linkage z etykietkami rzeczywistymi}\label{fig:agnesmdssingle2}
\end{figure}

Poniżej przedstawiamy macierz kontyngencji dla $k=2$.
<<echo=FALSE,results='asis'>>=
  tabelka.agnes.mds.single2<- table(agnes.mds.single.k2,etykietki.rzeczywiste)
print(xtable(tabelka.agnes.mds.single2, caption="Macierz kontyngencji - AGNES - single linkage", label="tab:etykagnessingle2"),type="latex",table.placement = "H",include.rownames = T)
@

  <<echo=FALSE>>=
  matchClasses(tabelka.agnes.mds.single2, method='exact')
@
Podobnie jak przy poprzedniej metodzie łączenia, jeden z klastrów jest bardzo mało liczny - jest tam zaledwie jedna obserwacja.

\subsubsection{complete linkage}
Rysunek \ref{fig:agnesmdscomplete} przedstawia dendrogram. Na Rysunku \ref{fig:agnesmdscomplete2} zaznaczyliśmy na dendrogramie klasy rzeczywiste.
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  agnes.mds.complete <- agnes(x=mds.k5,diss=FALSE,method="complete")
plot(agnes.mds.complete,which.plots=2,main="AGNES: complete linkage")
agnes.mds.complete.k2 <- cutree(agnes.mds.complete,k=2) 
@
  \caption{Dendrogram - AGNES - complete linkage}\label{fig:agnesmdscomplete}
\end{figure}

\begin{figure}[H]
<<echo=FALSE,fig=TRUE>>=
  hc.kol.mds.complete <- dendrapply(as.dendrogram(agnes.mds.complete), col.labels)
# rysuj dendrogram
par(cex=0.7)
plot(hc.kol.mds.complete)
legend("topright", legend=kolory.nazwy, col=1:3, pch=15, bg="azure2", cex=1.5)
@
  \caption{Dendrogram - AGNES - complete linkage z etykietkami rzeczywistymi}\label{fig:agnesmdscomplete2}
\end{figure}
Tabela \ref{tab:etykagnescomplete2} przedstawia macierz kontyngencji dla $k=2$.
<<echo=FALSE,results='asis'>>=
  tabelka.agnes.mds.complete2<- table(agnes.mds.complete.k2,etykietki.rzeczywiste)
print(xtable(tabelka.agnes.mds.complete2, caption="Macierz kontyngencji - AGNES - complete linkage", label="tab:etykagnescomplete2"),type="latex",table.placement = "H",include.rownames = T)
@
Z macierzy kontyngencji, możemy wyliczyć że do klastra pierwszego przypisano 227 obserwacji, a do drugiego 773. Mamy tu więc bardziej sensowny podział niż dla pozostałych metod łączenia .
  <<echo=FALSE>>=
  matchClasses(tabelka.agnes.mds.complete2, method='exact')
@
Procent zgodnych klas wynosi $62.5\%$.
  \subsection{DIANA}
Na Rysunkach \ref{fig:dianamds} i \ref{fig:dianamds2} znajdują się odpowiednio: dendrogram i dendrogram z klasami rzeczywistymi.
\begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  diana.mds <- diana(mds.k5,diss=FALSE)
par(cex=0.6)
plot(diana.mds,which.plot=2, main="DIANA")
@
  \caption{Dendrogram - DIANA}\label{fig:dianamds}
\end{figure}

<<echo=FALSE, fig=TRUE>>=
  # Odcinamy drzewo tak aby uzyskac dokladnie K=2 klastry
  diana.mds.k2 <- cutree(diana.mds,k=2) # etykietki klastrow
@
  
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE>>=
  hc.kol123 <- dendrapply(as.dendrogram(diana.mds), col.labels)

# rysuj dendrogram
par(cex=0.7)
plot(hc.kol123)
legend("topright", legend=kolory.nazwy, col=1:3, pch=15, bg="azure2", cex=1.5)
@
  \caption{Dendrogram - DIANA z etykietkami rzeczywistymi}\label{fig:dianamds2}
\end{figure}

<<echo=FALSE,results='asis'>>=
  tabelka.diana.mds2<- table(diana.mds.k2,etykietki.rzeczywiste)
print(xtable(tabelka.diana.mds2, caption="Macierz kontyngencji - DIANA", label="tab:etykdiana2"),type="latex",table.placement = "H",include.rownames = T)
@
  <<echo=FALSE>>=
  matchClasses(tabelka.diana.mds2, method='exact')
@
Po zastosowaniu algorytmu DIANA otrzymujemy dopasowanie na poziomie $53.2 \%$. Jest to słabszy wynik niż np. ten uzyskany metodą AGNES z complete linkage.
  \subsection{Ocena}
Przedstawimy teraz uzyskane za pomocą funkcji clValid wartości wybranych kryteriów dla metod k-means, PAM, DIANA, AGNES (average linkage) dla wartości $k=2, \ldots, 6$. W Tabeli \ref{tab:wsk1mds} znajdują się wskaźniki Connectivity, Dunn i Silhouette. Tabela \ref{tab:wsk2mds} przedstawia optymalną według danego kryterium liczbę klastrów i metodę. Ilustracja otrzymanych wyników znajduje się na Rysunku \ref{fig:ocenamds1}. 
<<echo=FALSE, warning=FALSE, results='asis'>>=
  library(clValid)
internal.validation.mds <- clValid(mds.k5,nClust=2:6,
                                   clMethods = c("kmeans","pam","diana","agnes"),validation = "internal",maxitems=1000)
#summary(internal.validation.mds)
mac1.mds <- as.data.frame(internal.validation.mds@measures)
mac11.mds <- mac1.mds
colnames(mac11.mds) <- c("k=2","k=3","k=4","k=5","k=6", "k=2","k=3","k=4","k=5","k=6", "k=2","k=3","k=4","k=5","k=6", "k=2","k=3","k=4","k=5","k=6")
mac.mds <- rbind(mac11.mds[,1:5], mac11.mds[,6:10], mac11.mds[,11:15], mac11.mds[,16:20])
v1<- c('Connectivity', 'Dunn', 'Silhouette', 'Connectivity', 'Dunn', 'Silhouette', 'Connectivity', 'Dunn', 'Silhouette', 'Connectivity', 'Dunn', 'Silhouette')
v<- c('kmeans', '', '',  'pam', '', '', 'diana', '', '', 'agnes', '', '' )
mac.mds <- cbind(v,v1, mac.mds)
colnames(mac.mds) <- c('method', "measure","k=2","k=3","k=4","k=5","k=6")
print(xtable(mac.mds,digits=3,caption="Wskaźniki wewnętrzne", label="tab:wsk1mds"),type="latex",table.placement = "H", include.rownames=FALSE)
@
  
  <<echo=FALSE,results='asis'>>=
  #optimalScores(internal.validation.mds)
  print(xtable(optimalScores(internal.validation.mds),digits=3,caption="Optymalne liczby klastrów i metoda w zależności od kryterium", label="tab:wsk2mds"
  ),type="latex",table.placement = "H")
@
  \begin{figure}[H]
<<echo=FALSE, fig=TRUE,fig.width=7, fig.height=8>>=
  par(mfrow=c(2,2))
plot(internal.validation.mds)
@
  \caption{Ocena jakości grupowania}\label{fig:ocenamds1}
\end{figure}

Według wskaźników Dunn i Silhouette optymalną metodą i liczbą klastrów jest k-means z $k=2$. Kryterium Connectivity wskazuje zaś na metodę AGNES z $k=2$. 

Sprawdzimy teraz wartości wskaźników stabilności: APN, AD, ADM i FOM. Zostały one przedstawione w Tabeli \ref{tab:wsk1mdsst}. Optymalna metoda i liczba klastrów według danego kryterium znajdują się w Tabeli \ref{tab:wsk4mds}. Rysunek \ref{fig:ocenamds2} ilustruje otrzymane wyniki.

<<echo=FALSE>>=
  stability.validation.mds <- clValid(mds.k5,nClust=2:6,
                                      clMethods = c("kmeans","pam","diana","agnes"),validation = "stability",maxitems=1000)
#summary(stability.validation.mds)
@
  <<echo=FALSE, results='asis'>>=
  mac2.mds <- as.data.frame(stability.validation.mds@measures)
mac21.mds <- mac2.mds
colnames(mac21.mds) <- c("k=2","k=3","k=4","k=5","k=6", "k=2","k=3","k=4","k=5","k=6", "k=2","k=3","k=4","k=5","k=6", "k=2","k=3","k=4","k=5","k=6")
mac.mds2 <- rbind(mac21.mds[,1:5], mac21.mds[,6:10], mac21.mds[,11:15], mac21.mds[,16:20])
v2<- c('APN', 'AD', 'ADM', 'FOM', 'APN', 'AD', 'ADM', 'FOM', 'APN', 'AD', 'ADM', 'FOM', 'APN', 'AD', 'ADM', 'FOM')
v3 <- c('kmeans', ' ', ' ', '',  'pam', ' ', ' ', '', 'diana', '','', '', 'agnes', '','', '' )
mac.mds2 <- cbind(v3,v2, mac.mds2)
colnames(mac.mds2) <- c('method',"measure","k=2","k=3","k=4","k=5","k=6")
print(xtable(mac.mds2,digits=3,caption="Wskaźniki stabilności", label="tab:wsk1mdsst"),type="latex",table.placement = "H", include.rownames=FALSE)
@
  
  <<echo=FALSE,results='asis'>>=
  #optimalScores(stability.validation.mds)
  print(xtable(optimalScores(stability.validation.mds),digits=3,caption="Optymalne liczby klastrów i metoda w zależności od kryterium", label="tab:wsk4mds"
  ),type="latex",table.placement = "H")
@
  \begin{figure}[H]
<<echo=FALSE,fig=TRUE,fig.width=7, fig.height=8>>=
  par(mfrow=c(2,2))
plot(stability.validation.mds)
@
  \caption{Ocena jakości grupowania}\label{fig:ocenamds2}
\end{figure}

Każdy z rozważanych wskaźników stabilności wybiera inną metodę z liczbą klastrów jako optymalną. Zauważmy jednak, że wartości FOM są bardzo zbliżone dla wszystkich metod. Z kolei rozważane wcześniej wskaźniki Dunn i Silhouette wskazują, że najlepszą metodą jest k-średnich. Także jeden ze wskaźników stabilności - AD wskazuje na ten algorytm. Warto zauważyć, że także procent zgodności klas rzeczywistych i przypisanych dla tej metody był wysoki. Była to jedyna metoda, przy której łatwo udało nam się znaleźć cechy charakteryzujące dane klastry. Dwa ostatnie stwierdzenia były prawdziwe również dla danych przed zastosowaniem MDS.

\section{Podsumowanie}
Analiza skupień jest bardzo wymagającym tematem, wymaga dużego nakładu pracy i doświadczenia. Analizy przeprowadzane przez różne osoby mogą znacząco się różnić. Co więcej, trudno wybrać optymalną liczbę klastrów, ponieważ istnieje bardzo dużo różnych sposobów oceny grupowania. Wybór metody grupowania także nie jest prosty. Warto jednak rozważać stosowanie redakcji wymiaru, gdyż w wielu przypadkach może polepszyć uzyskane rezultaty. \\
W przypadku analizowanych przez nas danych \textit{German Credit}, redukcja wymiaru poprzez zastosowanie skalowania wielowymiarowego sprawiła, że nastąpiła poprawa oceny dopasowywanych modeli klasyfikacji, jednak nie była ona znaczna. Należy również wziąć pod uwagę fakt, że stosując redukcję wymiaru utrudniamy interpretację otrzymywanych modeli. Ponadto w przypadku naszych danych, redukcja wymiaru poprzez MDS zmniejszyła wymiar o około połowę, co nie jest oszałamiającym rezultatem. Prawdopodobnie redukcja wymiaru ma większy sens, a być może nawet jej konieczna w przypadku, gdy dane mają bardzo dużą liczbę zmiennych, tak jak np. dane mikromacierzowe. Brak redukcji wymiaru może wówczas skutkować niemożnością dopasowania modelu klasyfikacji, na pewno zaś znacznie wydłuży czas obliczeń. U nas zastosowanie MDS skutkowało zazwyczaj pogorszeniem liczby zgodnych klas rzeczywistych i przypisanych. Może być to spowodowane utratą pewnej ilości informacji, z którą łączy się redukcja wymiaru. Wydaje się, że najlepsze rezultaty otrzymywaliśmy po zastosowaniu algorytmu k-means, zarówno przed jak i po zastosowaniu MDS. Mieliśmy wówczas najwyższą procentową zgodność klas rzeczywistych i przypisanych, a także łatwo udało nam się znaleźć cechy charakteryzujące dane klastry.

\end{document}